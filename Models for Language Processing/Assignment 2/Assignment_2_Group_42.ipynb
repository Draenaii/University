{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bZGhsX2c1Ped"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2 ([M4LP](https://osiris.uu.nl/osiris_student_uuprd/OnderwijsCatalogusSelect.do?selectie=cursus&collegejaar=2022&cursus=KI3V21001))\n",
        "\n",
        "The assignment covers lexical semantics and reasoning.  \n",
        "<font color=\"red\">**The rules to follow**:</font>  \n",
        "* Don't delete any initially provided cells, either text or code cells (but you should delete certain lines in the cells, continue reading).\n",
        "* Don't delete the exercise code header `#...# EXERCISE n #..#` lines and the `# TEST` lines. \n",
        "* Don't change the names of provided functions and variables. \n",
        "* If you skip an exercise, then delete all lines in the cell following the header `#...# EXERCISE n #..#` but leave its backup part--the line with `IFSKIPPED` and its following lines.\n",
        "* If you solve an exercise, then delete its corresponding backup part starting with `IFSKIPPED` and the following lines. \n",
        "* Use global vars throughout your code and change only those globals vars that are explicitly instructed. \n",
        "* For `#TEST` cells, if its output is coming from your code, then leave it; otherwise clear the output of the cell as it is uninformative and clutters the ipynb. \n",
        "* For Text cells, you are expected to insert your input only in the cells that come with a red section title. \n",
        "* Name the ipynb file with your group number, e.g., `01.ipynb` or `11.ipynb`.\n",
        "\n",
        "<font color=\"red\">You following these rules helps us to grade the submissions relatively efficiently. If these rules are violated, a submission will be subject to penalty points.</font>  \n",
        "\n",
        "<font color=\"red\">**IMPORTANT**</font>: you are strongly encouraged to use Google Colab when solving the exercises. Setting the common environment prevents students and teachers from various headaches related to cross-platform variations, module/package versioning, and unpredicted behaviour of the code. In this way, we try that you spend as much time as possible on coding during the course rather than on installations. Moreover, colab notebooks are very practical for group collaboration as they come with version history and several persons can work on the same notebook (not simultaneously though).  \n",
        "You are still free to solve the exercises on your own machine but in the end, make sure that your solutions also work in the colab environment. \n",
        "\n",
        "by L.abzianidze@uu.nl"
      ],
      "metadata": {
        "id": "7gbltP-WdxjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "~~Delete this text and write instead of it your:~~\n",
        "* ~~group number (same as the file name, for sanity chack)~~\n",
        "* ~~a list of group members names (NOT student IDs)~~\n",
        "* ~~who contributed to which exercises (you don't need to be very detailed)~~ "
      ],
      "metadata": {
        "id": "nNT1WNEnlkBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "_EU0aNkSBYGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "if spacy.__version__ != '3.5.2':\n",
        "    print(f\"spaCy v={spacy.__version__} but it should be 3.5.2\\nForce install 3.5.2 with the next cell\")"
      ],
      "metadata": {
        "id": "Ev0xSxOdzBTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# may require environment restart\n",
        "# !pip install spacy==3.5.2"
      ],
      "metadata": {
        "id": "SNxchUuszIOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3blhWf07xC1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d6f2ae-1358-4662-f0a0-441b73647ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-18 07:43:35.782259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "# may require environment restart\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assigntools package is a course specific collection of useful tools \n",
        "!rm -fr assigntools # helps to rerun this cell witthout errors, if recloning needed \n",
        "! git clone https://github.com/kovvalsky/assigntools.git"
      ],
      "metadata": {
        "id": "kPIBvjxg9aN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08536c7b-753d-4576-939b-9c1a38ff2063"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assigntools'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 228 (delta 10), reused 0 (delta 0), pack-reused 200\u001b[K\n",
            "Receiving objects: 100% (228/228), 55.48 KiB | 1.73 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import sys\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import spacy\n",
        "# Course-specific package\n",
        "from assigntools.M4LP.A1 import read_pickle, write_pickle\n",
        "from assigntools.M4LP.A2 import evaluate_contextual_lex_rel, taged2offsets, show_tableau, LangPro"
      ],
      "metadata": {
        "id": "m267kLd0Bv1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef99933-d91f-4512-fcda-950546f8ca69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST\n",
        "print(f\"spaCy version: {spacy.__version__}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"NLTK version: {nltk.__version__}\")"
      ],
      "metadata": {
        "id": "P3JBRKtzxSRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0723ee-2d99-40b2-df62-8d8bc825137a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy version: 3.5.2\n",
            "Python version: 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
            "NLTK version: 3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User modules\n",
        "\n",
        "Import all modules here what you might need in addition to what is already imported."
      ],
      "metadata": {
        "id": "HcD8C5xA1isO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT ALL ADDED AND NECESSARY MODULES HERE (IF ANY)\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "# assigntools package is a course specific collection of useful tools \n",
        "!rm -fr assigntools # helps to rerun this cell witthout errors, if recloning needed \n",
        "! git clone https://github.com/kovvalsky/assigntools.git\n",
        "\n",
        "import nltk\n",
        "import sys\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import spacy\n",
        "# Course-specific package\n",
        "from assigntools.M4LP.A1 import read_pickle, write_pickle\n",
        "from assigntools.M4LP.A2 import evaluate_contextual_lex_rel, taged2offsets, show_tableau, LangPro"
      ],
      "metadata": {
        "id": "pTz2S1M61vAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981ba9b4-9e9c-4450-89fc-b99f9c07e03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-18 07:44:21.158881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "Cloning into 'assigntools'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 228 (delta 10), reused 0 (delta 0), pack-reused 200\u001b[K\n",
            "Receiving objects: 100% (228/228), 55.48 KiB | 4.27 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WordNet"
      ],
      "metadata": {
        "id": "WvRSNrv9FTPY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkIOb4z--VDV"
      },
      "source": [
        "The code shows how to get the noun(!) sysnsets for `lecture` and for each sysnset to show its definition and examples and to list its word senses. This code attempts to show how to get all the info what is displayed in the [online results](http://wordnetweb.princeton.edu/perl/webwn?s=lecture&sub=Search+WordNet&o2=&o0=1&o8=1&o1=1&o7=1&o5=&o9=&o6=&o3=&o4=&h=00000).\n",
        "More details about `wn.Synset` and `wn.Lemma` classes can be found [here](https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html) and [here](https://www.nltk.org/howto/wordnet.html).  \n",
        "<font color=\"red\">It is important that you understand this code well as it will help you with other WordNet exercises</font>.  \n",
        "Note that NLTK uses WordNet 3.0 while the online browser 3.1. So, if there are some mismatches between these two, one of the reasons can be different versions.  \n",
        "If you prefer more graphical visualization of wordnet, check [visuwords](https://visuwords.com/). Warning: it might get pretty messy when large synsets are explored.  \n",
        "Definitions of certain technical terms of WordNet can be looked up [here](https://wordnet.princeton.edu/documentation/wngloss7wn)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_mqDU35DUMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89f68ae-b8cf-41e4-a7ba-0c669bd4e223"
      },
      "source": [
        "for synset in wn.synsets('lecture', pos=wn.NOUN):\n",
        "    all_examples = ','.join([ f'\"{e}\"' for e in synset.examples() ])\n",
        "    print(f'{synset}:\\n\\t({synset.definition()})\\n\\t{all_examples}')\n",
        "    # for l in synset.lemmas():\n",
        "    #     # find a sense number of the lemma of the target synset.\n",
        "    #     # For this, first, we find all synsets for this lemma and \n",
        "    #     # in this synset list we find the position+1 of the target synset \n",
        "    #     all_synsets_of_l = wn.synsets(l.name())\n",
        "    #     sense_num = all_synsets_of_l.index(l.synset()) + 1\n",
        "    #     print(f\"\\t{l.name()}#{sense_num}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('lecture.n.01'):\n",
            "\t(a speech that is open to the public)\n",
            "\t\"he attended a lecture on telecommunications\"\n",
            "Synset('lecture.n.02'):\n",
            "\t(a lengthy rebuke)\n",
            "\t\"a good lecture was my father's idea of discipline\",\"the teacher gave him a talking to\"\n",
            "Synset('lecture.n.03'):\n",
            "\t(teaching by giving a discourse on some subject (typically to a class))\n",
            "\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contextual lexical relation\n",
        "\n",
        "We will be working with the `context_ppdb` dataset from [Shwartz et al (2016)](https://aclanthology.org/S16-2013/). The examples from the dataset can be found in Table 1 of the paper and in the dataset itself. It is also recommended to read `README.txt` found in the dataset archive. We will use `dataset.tsv` file for the exercise (as we are not doing any model training).\n",
        "\n",
        "In a nutshell, the task is to guess a lexical relation that holds between the senses of `x` and `y` that they have in their corresponding contexts. We will divide the task into two tasks. First will be the word sense disambiguation (WSD) for `x/y` in their contexts, and the second will be to predict a lexical relation between the word senses based on WordNet."
      ],
      "metadata": {
        "id": "l_e10o69uisu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the context_ppdb dataset\n",
        "!wget https://naturallogic.pro/_files_/download/context_ppdb_fine_human_precise.zip\n",
        "!unzip -o context_ppdb_fine_human_precise.zip -d context_ppdb"
      ],
      "metadata": {
        "id": "3WVcIUZfJsRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a984c16-7c5b-4979-9c4d-21d01a216010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-17 08:34:12--  https://naturallogic.pro/_files_/download/context_ppdb_fine_human_precise.zip\n",
            "Resolving naturallogic.pro (naturallogic.pro)... 85.214.116.22\n",
            "Connecting to naturallogic.pro (naturallogic.pro)|85.214.116.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1029651 (1006K) [application/zip]\n",
            "Saving to: ‘context_ppdb_fine_human_precise.zip’\n",
            "\n",
            "context_ppdb_fine_h 100%[===================>]   1006K  1.35MB/s    in 0.7s    \n",
            "\n",
            "2023-05-17 08:34:13 (1.35 MB/s) - ‘context_ppdb_fine_human_precise.zip’ saved [1029651/1029651]\n",
            "\n",
            "Archive:  context_ppdb_fine_human_precise.zip\n",
            "  inflating: context_ppdb/README.txt  \n",
            "  inflating: context_ppdb/test.tsv   \n",
            "  inflating: context_ppdb/train.tsv  \n",
            "  inflating: context_ppdb/validation.tsv  \n",
            "  inflating: context_ppdb/dataset.tsv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# viewing top 10 lines of the dataset\n",
        "!head context_ppdb/dataset.tsv"
      ],
      "metadata": {
        "id": "zXsMRUMuSnGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1438ee-f125-4c7d-c0bd-7601c1b0bab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bicycle\triding\tBolotta recounted finding 22 sharpened <x>bicycle</x> spokes jabbed into the lawn while she was out with the lawn mower.\tA lesser known work of Hopper's, 'Bridal Path' shows a horseback <y>riding</y> path in Central Park.\tother-related\t0.6\n",
            "photo\tpicture\tSome of the mission will include examining the surface for sources of water, and taking comparison <x>photos</x> of the light side and dark sides of the surface.\tThe trial judge, His Honour Judge Michael Murphy QC, who had previously ordered the jury not to consult the Internet, did not halt the prosecution as he felt 'satisfied' the jury hadn't seen the <y>picture</y>.\tequivalence\t1.0\n",
            "catch\tfish\tDepartment officer Chris Mitchell says the fishermen had traversed 200 miles of Commonwealth waters and were inside the three nautical mile state limit when they were <x>caught</x>.\tA 375 million-year old fossilised umbilical cord indicates that placoderm, thought to be ancestors of modern <y>fish</y>, are actually closer to sharks and rays.\tindependent\t1.0\n",
            "fire\tpolice\tThe submarine had 208 people aboard—three times the normal crew—when the <x>fire</x> fighting system was triggered by an unknown cause, flooding a forward compartment with Freon gas which is used to extinguish fires by removing oxygen from the atmosphere.\tThe <y>police</y> have said that there are 100 dead in Chennai city alone.\tindependent\t1.0\n",
            "boy\tchild\tHe married a woman he meet at college, Norma Kaphan and they had two <x>boys</x>, Peter and Christopher.\tThe court found that he, along with his son Franck V. and Franck's former spouse, Patricia M., was one the instigators of a sex ring that abused 45 <y>children</y>, mostly in the couple's flat.\tforward_entailment\t1.0\n",
            "fun\tswing\tHowever, mathematics enthusiasts often seek them for <x>fun</x>, and the GIMPS community is already looking forward to finding a 100 million digit prime that will qualify for a $150,000 prize from the EFF. Great Internet Mersenne Prime Search\tThe ride is called a 'LollySwing', which is located in Kiddyland, where the riders sit in <y>swings</y> while the machine spins them around.\tindependent\t0.6\n",
            "car\twindows\tMogale's crimes lasted a year from March 2008 to March 2009, coming to an end when police were passed his <x>car</x>'s number plate information following a teen's disappearance.\tFour men attacked patrons of a Pizzeria, knocking a woman unconscious on the footpath and smashing <y>windows</y>.\tindependent\t1.0\n",
            "talk\tphone\tGoogle, Yahoo, and Canonical also gave <x>talks</x> about Google Gears, Yahoo UI, and Ubuntu Mobile.\tThe post of controller became vacant last year when Lesley Douglas resigned following the scandal over crude <y>phone</y> calls made by Russell Brand and Jonathan Ross to actor Andrew Sachs during a pre-recorded music programme.\tindependent\t0.6\n",
            "boat\tvehicle\tThe river is closed to <x>boats</x> as rescue operations continue, and a 22-strong team has been dispatched from the national police, comprising six forensics experts, five disaster victim identification specialists, and eleven investigators.\tAccording to BBC Cambridgeshire presenter Chris Mann, the car 'suddenly accelerated' into the rear of the <y>vehicle</y>.\tforward_entailment\t0.8\n",
            "market\toil\tAnalysts noted that this move has the potential to financially hurt Google, which has a somewhat limited share of the Internet search <x>market</x> in China, which is dominated by the Chinese-based Google-like website Baidu.\tThe United States government has filed a civil lawsuit against BP Exploration (Alaska) Inc. (BPXA) alleging that the company 'violated federal clean air and water laws' by 'illegally discharging' more than 200,000 gallons crude <y>oil</y> during two <y>oil</y> spills in 2006 on Alaska's North Slope in Prudhoe Bay.\tindependent\t0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex1[2pt]: Reading data\n",
        "\n",
        "Write `read_data` function to read data from the file. Before reading the data from the file, understand the content & format of the file. \n",
        "It is not a good practice when the original texts are changed, like in this dataset, where tags `<x>` and `<y>` are used to mark occurences of target words. Because of this, we first need to clean the texts from the tags but save the character offsets of the tagged tokens (to avoid information loss). The cleaned sentences will later be used as an input to spaCy.  \n",
        "To help you with replacing tagged word info with character offsets, we provide you a ready function [tagged2offsets](https://github.com/kovvalsky/assigntools/blob/main/M4LP/A2.py) that does this (it was imported in the beginning). "
      ],
      "metadata": {
        "id": "BjhmgMAMT4Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST: a real example from the dataset\n",
        "s = \"Studies have shown that <x>drinks</x>, especially sweetened, contribute to obesity among adults and children, leading to diseases like diabetes. 'Eight out of ten <x>drinks</x> sold in California public schools are sports <x>drinks</x>,' Padilla said, citing information from the California Department of Public Health.\"\n",
        "cleaned_s, offsets = taged2offsets(\"x\", s)\n",
        "print(cleaned_s)\n",
        "for start, end in offsets:\n",
        "    print(f\"{cleaned_s[start:end]} at {start}:{end}\")"
      ],
      "metadata": {
        "id": "98-wRUYVArlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761226d9-32ce-40f9-9c61-1bdce39fda4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Studies have shown that drinks, especially sweetened, contribute to obesity among adults and children, leading to diseases like diabetes. 'Eight out of ten drinks sold in California public schools are sports drinks,' Padilla said, citing information from the California Department of Public Health.\n",
            "drinks at 24:30\n",
            "drinks at 156:162\n",
            "drinks at 208:214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Studies have shown that drinks, especially sweetened, contribute to obesity among adults and children, leading to diseases like diabetes. 'Eight out of ten drinks sold in California public schools are sports drinks,' Padilla said, citing information from the California Department of Public Health.\n",
        "drinks at 24:30\n",
        "drinks at 156:162\n",
        "drinks at 208:214\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "qUbvTQgw3ypL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "################################## EXERCISE 1 ##################################\n",
        "################################################################################\n",
        "\n",
        "def read_data(file_path):\n",
        "    \"\"\" Read the samples from the data file.\n",
        "        Return a list of samples, where each list element is a dictionary\n",
        "        {'x':(x, tag_free_context_x, offsets_x), 'y':(y, tag_free_context_y, offsets_y), \n",
        "         'r':semantic_relation, 'c':confidence }.\n",
        "        x and y are target words for left and right contexts while \n",
        "        tag_free_context_* are corresponding context sentences without <x/y> tags.\n",
        "        offsets_x/y give positions of tagged words in the tag_free_context_x/y  \n",
        "    \"\"\"\n",
        "    with open(file_path) as file:\n",
        "      lijst = []\n",
        "      for line in file:\n",
        "        lsplit = line.split('\\t')\n",
        "\n",
        "        tag_free_context_x, offsets_x = taged2offsets(\"x\", lsplit[2])\n",
        "        tag_free_context_y, offsets_y = taged2offsets(\"y\", lsplit[3])\n",
        "\n",
        "        lijst.append({'x':(lsplit[0], tag_free_context_x, offsets_x), 'y':(lsplit[1], tag_free_context_y, offsets_y), \n",
        "                      'r':lsplit[4], 'c':lsplit[5].strip()})\n",
        "    return lijst"
      ],
      "metadata": {
        "id": "S0miS-XKTnDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data('context_ppdb/dataset.tsv')"
      ],
      "metadata": {
        "id": "cnlmq-gt-bPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST EX1: compare(!) this output to the corresponding lines in the data file\n",
        "# in order to better understand what kind of (weird) samples the data contains\n",
        "print(data[0])\n",
        "print(data[667])\n",
        "print(data[766])\n",
        "print(data[3338])\n",
        "print(f\"The data size = {len(data)}\")"
      ],
      "metadata": {
        "id": "6VPvhOMDNlck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723c3b8f-fde9-4154-df1f-7ff6ab53730c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': ('bicycle', 'Bolotta recounted finding 22 sharpened bicycle spokes jabbed into the lawn while she was out with the lawn mower.', [(39, 46)]), 'y': ('riding', \"A lesser known work of Hopper's, 'Bridal Path' shows a horseback riding path in Central Park.\", [(65, 71)]), 'r': 'other-related', 'c': '0.6'}\n",
            "{'x': ('girl', 'One girl is still missing.', [(4, 8)]), 'y': ('woman', \"Activists have sought women's right to vote in Saudi Arabia for years.\", [(22, 27)]), 'r': 'other-related', 'c': '0.6'}\n",
            "{'x': ('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.', [(60, 66)]), 'y': ('child', 'He is survived by three children, along with grandchildren and great-grandchildren.', [(24, 32), (50, 58), (74, 82)]), 'r': 'other-related', 'c': '0.8'}\n",
            "{'x': ('goal', 'Scientific goals.', [(11, 16)]), 'y': ('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\", [(25, 31)]), 'r': 'independent', 'c': '0.8'}\n",
            "The data size = 3404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'x': ('bicycle', 'Bolotta recounted finding 22 sharpened bicycle spokes jabbed into the lawn while she was out with the lawn mower.', [(39, 46)]), 'y': ('riding', \"A lesser known work of Hopper's, 'Bridal Path' shows a horseback riding path in Central Park.\", [(65, 71)]), 'r': 'other-related', 'c': '0.6'}\n",
        "{'x': ('girl', 'One girl is still missing.', [(4, 8)]), 'y': ('woman', \"Activists have sought women's right to vote in Saudi Arabia for years.\", [(22, 27)]), 'r': 'other-related', 'c': '0.6'}\n",
        "{'x': ('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.', [(60, 66)]), 'y': ('child', 'He is survived by three children, along with grandchildren and great-grandchildren.', [(24, 32), (50, 58), (74, 82)]), 'r': 'other-related', 'c': '0.8'}\n",
        "{'x': ('goal', 'Scientific goals.', [(11, 16)]), 'y': ('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\", [(25, 31)]), 'r': 'independent', 'c': '0.8'}\n",
        "The data size = 3404\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "hG-JLMoL342j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST: we also provide you with a function that evaluates predicted relations\n",
        "# wrt the gold relations in data. Let's see if one always predicts 'independent'\n",
        "# relation, what will be its accuracy and confusion matrix wrt the gold relations\n",
        "evaluate_contextual_lex_rel(['independent']*len(data), data, draw=True)\n",
        "# Note that 'independent' is the majority class baseline "
      ],
      "metadata": {
        "id": "x2lDPm9vBqCC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "583ab886-dabf-4d79-9372-9eea338739c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5276145710928319"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex2[4pt]: Processing with spaCy\n",
        "\n",
        "In order to guess the sense of a word in a context, it is helpful to know its POS tag. To find out the POS tags, we process context sentences with spaCy. To make processing faster, you can use `.pipe()` method (see Assignmnet 1) to parse all sentences in a single run.  \n",
        "Note that we use `en_core_web_md` as it is the smallest model that comes with word vectors (and we will use them in latter exercises). "
      ],
      "metadata": {
        "id": "vrWnexJie9JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "################################## EXERCISE 2 ##################################\n",
        "################################################################################\n",
        "\n",
        "def spacy_process(data):\n",
        "    \"\"\" Takes the data variable as an input and processes the sentences with spacy.\n",
        "        Returns a list of samples, where each sample is a dictionary\n",
        "        {'x': (pos_x, doc_x), 'y': (pos_y, doc_y)}, where pos and doc are\n",
        "        spaCy's pos tag (token.pos_) for a corresponging target word and \n",
        "        Doc object of the corresponding sentecne. \n",
        "        Sometimes target words have several occurences in a sentence \n",
        "        that might get different pos tags. In this case, for the sake of determinism,\n",
        "        pick the first from the alphabetical order, e.g., ADJ is prefered over NOUN.\n",
        "        The list order follows the order of samples in the data  \n",
        "    \"\"\"\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "    lijst = []\n",
        "    x_clean = []\n",
        "    y_clean = []\n",
        "\n",
        "    for line in data:\n",
        "      x_clean.append(line['x'][1])\n",
        "      y_clean.append(line['y'][1])\n",
        "\n",
        "    doc_x_lijst = list(nlp.pipe(x_clean))\n",
        "    doc_y_lijst = list(nlp.pipe(y_clean))\n",
        "\n",
        "    i = 0\n",
        "    for line in data:\n",
        "      pos_x_lijst = []\n",
        "      pos_y_lijst = []\n",
        "      char_spans_x = line['x'][2]\n",
        "      char_spans_y = line['y'][2]\n",
        "\n",
        "      doc_x = doc_x_lijst[i]\n",
        "      for start_char, end_char in char_spans_x:\n",
        "          word_span = doc_x.char_span(start_char, end_char)\n",
        "          if word_span is not None:\n",
        "              word_tokens = [token for token in doc_x if token.idx >= start_char and token.idx < end_char]\n",
        "              pos_tags_for_word = [token.pos_ for token in word_tokens]\n",
        "              pos_x_lijst.append(pos_tags_for_word)\n",
        "\n",
        "      doc_y = doc_y_lijst[i]\n",
        "      for start_char, end_char in char_spans_y:\n",
        "          word_span = doc_y.char_span(start_char, end_char)\n",
        "          if word_span is not None:\n",
        "              word_tokens = [token for token in doc_y if token.idx >= start_char and token.idx < end_char]\n",
        "              pos_tags_for_word = [token.pos_ for token in word_tokens]\n",
        "              pos_y_lijst.append(pos_tags_for_word)\n",
        "\n",
        "      i = i + 1\n",
        "      lijst.append({'x': (sorted(pos_x_lijst)[0][0], doc_x), 'y': (sorted(pos_y_lijst)[0][0], doc_y)})\n",
        "\n",
        "    return lijst"
      ],
      "metadata": {
        "id": "sGyP8uebe9TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST\n",
        "data[0]"
      ],
      "metadata": {
        "id": "nHOOzSdJTtl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a76e13-7001-43ed-c183-a6d4b4a23a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': ('bicycle',\n",
              "  'Bolotta recounted finding 22 sharpened bicycle spokes jabbed into the lawn while she was out with the lawn mower.',\n",
              "  [(39, 46)]),\n",
              " 'y': ('riding',\n",
              "  \"A lesser known work of Hopper's, 'Bridal Path' shows a horseback riding path in Central Park.\",\n",
              "  [(65, 71)]),\n",
              " 'r': 'other-related',\n",
              " 'c': '0.6'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'x': ('bicycle',\n",
        "  'Bolotta recounted finding 22 sharpened bicycle spokes jabbed into the lawn while she was out with the lawn mower.',\n",
        "  [(39, 46)]),\n",
        " 'y': ('riding',\n",
        "  \"A lesser known work of Hopper's, 'Bridal Path' shows a horseback riding path in Central Park.\",\n",
        "  [(65, 71)]),\n",
        " 'r': 'other-related',\n",
        " 'c': '0.6'}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EF1WyvYg4GxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# takes ~40 sec with .pipe()\n",
        "docs_data = spacy_process(data)"
      ],
      "metadata": {
        "id": "pmyD4ZZeAsXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST\n",
        "print(data[766]['y'])\n",
        "print(docs_data[766]['y'])\n",
        "print(f\"{'-':-^20}\")\n",
        "print(data[3068]['x'])\n",
        "print(docs_data[3068]['x'])\n",
        "print(f\"{'-':-^20}\")\n",
        "print(data[3338]['x'])\n",
        "print(docs_data[3338]['x'])"
      ],
      "metadata": {
        "id": "3sCf1Q3tcpTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a0137b-c1de-4e1c-b8bb-f0fe96fda265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.', [(24, 32), (50, 58), (74, 82)])\n",
            "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
            "--------------------\n",
            "('front', \"Several officers in white forensic suits were examining the barricaded area and a huge white tent was erected in front of the house's front door.\", [(113, 118), (134, 139)])\n",
            "('ADJ', Several officers in white forensic suits were examining the barricaded area and a huge white tent was erected in front of the house's front door.)\n",
            "--------------------\n",
            "('goal', 'Scientific goals.', [(11, 16)])\n",
            "('NOUN', Scientific goals.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.', [(24, 32), (50, 58), (74, 82)])\n",
        "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
        "--------------------\n",
        "('front', \"Several officers in white forensic suits were examining the barricaded area and a huge white tent was erected in front of the house's front door.\", [(113, 118), (134, 139)])\n",
        "('ADJ', Several officers in white forensic suits were examining the barricaded area and a huge white tent was erected in front of the house's front door.)\n",
        "--------------------\n",
        "('goal', 'Scientific goals.', [(11, 16)])\n",
        "('NOUN', Scientific goals.)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "96Uzx7s74L_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST EX2 \n",
        "#checking what is the counts of pos tags assigned by spaCy en_core_web_md(!) to the target words \n",
        "from collections import Counter\n",
        "\n",
        "word_pos_cnt = Counter(s[i][0] for s in docs_data for i in 'xy' )\n",
        "print(word_pos_cnt)\n",
        "print(f\"{sum(word_pos_cnt.values())} pos tagged words show that we have tags for all target words\")"
      ],
      "metadata": {
        "id": "4fgzlrD_krRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562932e9-7b47-434f-cbff-f4c25b3621eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NOUN': 4921, 'VERB': 946, 'PROPN': 765, 'ADJ': 174, 'INTJ': 2})\n",
            "6808 pos tagged words show that we have tags for all target words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Counter({'NOUN': 4921, 'VERB': 946, 'PROPN': 765, 'ADJ': 174, 'INTJ': 2})\n",
        "6808 pos tagged words show that we have tags for all target words\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vrSiND9g4gb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WSD\n",
        "\n",
        "After we have processed context sentences, we have POS tags for the target words. This will help us to narrow down the search space of word senses. Now it is time to do Word Sense Disambiguation (WSD) for each word in its context sentence. You are supposed to write three functions that predict WordNet sense for each word in the context for the entire data. Each of these functions take `data` and `docs_data` and returns a list of dictionaries with synsets of `x` and `y` words. The functions will differ the way they predict senses. \n",
        "\n",
        "\n",
        "* `most_frequent_sense()` - picks the first sense of the word, which is also the most frequent sense of the word.pos (i.e., word.pos.01).\n",
        "* `simple_lesk_sense()` - picks the sense whose description and/or examples has largest overlap with the context sentence.\n",
        "* `vector_lesk_sesne()` - picks the sense whose description and/or examples vector is most similar to the vector of the context sentence.\n",
        "\n",
        "<font color=\"red\">IMPORTANT</font>: WordNet covers the words belonging to four classes (noun, verb, adjective, and adverb). In case spaCy assigned a POS tag that is none of these four, the wsd functions should be able to have some fallback pos tag in such cases to avoid runtime errors. Noun is a good option for such a fallback pos tag. For example, if a word gets proper name POS tag, a wsd can assume that its tag is Noun.\n",
        "\n",
        "Note that whether the WordNet description and examples are used alone or together, it is up to you. If you want to have a relativelyt high-performing system in the end, you might want to explore different settings.  \n",
        "\n",
        "Potentially useful links: [link1](https://github.com/Akirato/Lesk-Algorithm/blob/master/leskAlgorithm.py), [link2](https://medium.com/analytics-vidhya/comparative-word-sense-disambiguation-1c3f0f4be1fa), [link3](https://www.nltk.org/howto/wsd.html)\n",
        "\n"
      ],
      "metadata": {
        "id": "vu2mvasrXWdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex3[3pt]: Most frequent sense"
      ],
      "metadata": {
        "id": "SPRGs97Fjdxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "################################## EXERCISE 3 ##################################\n",
        "################################################################################\n",
        "\n",
        "def most_frequent_sense(data, docs_data):\n",
        "    \"\"\" Takes data and docs_data, and return a list of dictionaries\n",
        "        {'x': synset_of_x, 'y': synset_of_y } where synset_of_x/y is \n",
        "        the first sense of x/y in the context_x/y.\n",
        "        Note that pos tag of x/y is retrieved from docs_data and used\n",
        "        to restric the possible senses for a word.\n",
        "        If synset_of_x/y cannot be found (e.g., x/y is an unknown word), \n",
        "        return None for the corresponding x/y key.\n",
        "        The order in the returned list follows the orders in data and docs_data.\n",
        "    \"\"\"\n",
        "    wordx, wordy, posx, posy, lijst = [], [], [], [], []\n",
        "\n",
        "    for line in data:\n",
        "      wordx.append(line['x'][0])\n",
        "      wordy.append(line['y'][0])\n",
        "\n",
        "    for line in docs_data:\n",
        "      xpos = line['x'][0]\n",
        "      if xpos == 'NOUN':\n",
        "        posx.append('n')\n",
        "      elif xpos == 'VERB':\n",
        "        posx.append('v')\n",
        "      elif xpos == 'ADJ':\n",
        "        posx.append('a')\n",
        "      else:\n",
        "        posx.append('n')\n",
        "    \n",
        "      ypos = line['y'][0]\n",
        "      if ypos == 'NOUN':\n",
        "        posy.append('n')\n",
        "      elif ypos == 'VERB':\n",
        "        posy.append('v')\n",
        "      elif ypos == 'ADJ':\n",
        "        posy.append('a')\n",
        "      else:\n",
        "        posy.append('n')\n",
        "\n",
        "    for i in range(len(wordx)):\n",
        "      synsetsx = [(s, s.pos()) for s in wn.synsets(wordx[i])]\n",
        "      synsetx = None\n",
        "      for synset in synsetsx:\n",
        "        if synset[1] == posx[i]:\n",
        "          synsetx = synset[0]\n",
        "          break\n",
        "      \n",
        "      synsetsy = [(s, s.pos()) for s in wn.synsets(wordy[i])]\n",
        "      synsety = None\n",
        "      for synset in synsetsy:\n",
        "        if synset[1] == posy[i]:\n",
        "          synsety = synset[0]\n",
        "          break\n",
        "      \n",
        "      \n",
        "      lijst.append({'x': synsetx, 'y': synsety})\n",
        "    return lijst"
      ],
      "metadata": {
        "id": "rJeiZ0kpXUtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MFS_data = most_frequent_sense(data, docs_data)"
      ],
      "metadata": {
        "id": "AD5lFhcd6AfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST EX3: note that in this output, \"sit\" in 628_x is identifiet as Noun but\n",
        "# WordNet doesn't have noun sense of \"sit\", hence the synset is None\n",
        "for i in [628, 766, 3338]:\n",
        "    for xy in 'xy':\n",
        "        print(data[i][xy][:2])\n",
        "        print(docs_data[i][xy])\n",
        "        print(MFS_data[i][xy])\n",
        "    print(f\"{'':-^20}\")"
      ],
      "metadata": {
        "id": "f0QJYPd0oDCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5a425f-db2f-4ea9-cb1a-f005f45cd675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('sit', 'In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.')\n",
            "('NOUN', In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.)\n",
            "None\n",
            "('stand', 'It was worth my while to try to stand up and punch with him.')\n",
            "('VERB', It was worth my while to try to stand up and punch with him.)\n",
            "Synset('stand.v.01')\n",
            "--------------------\n",
            "('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.')\n",
            "('NOUN', Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.)\n",
            "Synset('family.n.01')\n",
            "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.')\n",
            "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
            "Synset('child.n.01')\n",
            "--------------------\n",
            "('goal', 'Scientific goals.')\n",
            "('NOUN', Scientific goals.)\n",
            "Synset('goal.n.01')\n",
            "('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\")\n",
            "('NOUN', Fans of the Netherlands' soccer team were wildly celebrating too.)\n",
            "Synset('soccer.n.01')\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "('sit', 'In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.')\n",
        "('NOUN', In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.)\n",
        "None\n",
        "('stand', 'It was worth my while to try to stand up and punch with him.')\n",
        "('VERB', It was worth my while to try to stand up and punch with him.)\n",
        "Synset('stand.v.01')\n",
        "--------------------\n",
        "('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.')\n",
        "('NOUN', Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.)\n",
        "Synset('family.n.01')\n",
        "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.')\n",
        "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
        "Synset('child.n.01')\n",
        "--------------------\n",
        "('goal', 'Scientific goals.')\n",
        "('NOUN', Scientific goals.)\n",
        "Synset('goal.n.01')\n",
        "('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\")\n",
        "('NOUN', Fans of the Netherlands' soccer team were wildly celebrating too.)\n",
        "Synset('soccer.n.01')\n",
        "--------------------\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6xsSlXzvRmG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex4[3pt]: Simple Lesk\n",
        "\n",
        "Simplest is to use [NLTK's Lesk](https://www.nltk.org/howto/wsd.html). You can read more about Lesk Algorithm [here](https://en.wikipedia.org/wiki/Lesk_algorithm). You are also welcome to write your own Lesk version as NLTK's one is not performing well."
      ],
      "metadata": {
        "id": "s6vkW4WejT51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "################################## EXERCISE 4 ##################################\n",
        "################################################################################\n",
        "from nltk.wsd import lesk\n",
        "\n",
        "def simple_lesk_sense(data, docs_data):\n",
        "    \"\"\" Takes data and docs_data, and return a list of dictionaries\n",
        "        {'x': synset_of_x, 'y': synset_of_y } where synset_of_x/y is \n",
        "        the sense of x/y in the context_x/y detecting by Lesk-like algorithm,\n",
        "        which selects a sense based on the size of the overlap between the\n",
        "        context and the definition and/or examples of the possible synsets.\n",
        "        Note that pos tag of x/y is retrieved from docs_data and used\n",
        "        to restric the possible senses for a word.\n",
        "        The order in the returned list follows the orders in data and docs_data.\n",
        "    \"\"\"\n",
        "    lijst = []\n",
        "    posx = []\n",
        "    posy = []\n",
        "\n",
        "    for line in docs_data:\n",
        "      xpos = line['x'][0]\n",
        "      if xpos == 'NOUN':\n",
        "        posx.append('n')\n",
        "      elif xpos == 'VERB':\n",
        "        posx.append('v')\n",
        "      elif xpos == 'ADJ':\n",
        "        posx.append('a')\n",
        "      else:\n",
        "        posx.append('n')\n",
        "    \n",
        "      ypos = line['y'][0]\n",
        "      if ypos == 'NOUN':\n",
        "        posy.append('n')\n",
        "      elif ypos == 'VERB':\n",
        "        posy.append('v')\n",
        "      elif ypos == 'ADJ':\n",
        "        posy.append('a')\n",
        "      else:\n",
        "        posy.append('n') \n",
        "\n",
        "    i = 0\n",
        "    for line in data:\n",
        "      lijst.append({'x': lesk((line['x'][1].split()), (line['x'][0]), posx[i]), 'y': lesk((line['y'][1].split()), (line['y'][0]), posy[i])})\n",
        "      i = i + 1\n",
        "      \n",
        "    return lijst"
      ],
      "metadata": {
        "id": "qB_CjuwmeTOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIMPLE_LESK_data = simple_lesk_sense(data, docs_data)"
      ],
      "metadata": {
        "id": "hPQ__OQ7Fg1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST EX4\n",
        "# These are the same data samples as the ones above.\n",
        "# compare sense predictions from this to the previous function(s) and find the difference\n",
        "# IMPORTANT: depending on certain choice points, you might not get exactly the same\n",
        "# output as below and that's fine. \n",
        "for i in [628, 766, 3338]:\n",
        "    for xy in 'xy':\n",
        "        print(data[i][xy][:2])\n",
        "        print(docs_data[i][xy])\n",
        "        print(SIMPLE_LESK_data[i][xy])\n",
        "    print(f\"{'':-^20}\")"
      ],
      "metadata": {
        "id": "-lf-Rz06H0iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33b25df-48a4-490e-ef02-d0f0d76ccd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('sit', 'In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.')\n",
            "('NOUN', In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.)\n",
            "None\n",
            "('stand', 'It was worth my while to try to stand up and punch with him.')\n",
            "('VERB', It was worth my while to try to stand up and punch with him.)\n",
            "Synset('digest.v.03')\n",
            "--------------------\n",
            "('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.')\n",
            "('NOUN', Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.)\n",
            "Synset('syndicate.n.01')\n",
            "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.')\n",
            "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
            "Synset('child.n.04')\n",
            "--------------------\n",
            "('goal', 'Scientific goals.')\n",
            "('NOUN', Scientific goals.)\n",
            "Synset('goal.n.04')\n",
            "('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\")\n",
            "('NOUN', Fans of the Netherlands' soccer team were wildly celebrating too.)\n",
            "Synset('soccer.n.01')\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "('sit', 'In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.')\n",
        "('NOUN', In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.)\n",
        "None\n",
        "('stand', 'It was worth my while to try to stand up and punch with him.')\n",
        "('VERB', It was worth my while to try to stand up and punch with him.)\n",
        "Synset('digest.v.03')\n",
        "--------------------\n",
        "('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.')\n",
        "('NOUN', Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.)\n",
        "Synset('syndicate.n.01')\n",
        "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.')\n",
        "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
        "Synset('child.n.04')\n",
        "--------------------\n",
        "('goal', 'Scientific goals.')\n",
        "('NOUN', Scientific goals.)\n",
        "Synset('goal.n.04')\n",
        "('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\")\n",
        "('NOUN', Fans of the Netherlands' soccer team were wildly celebrating too.)\n",
        "Synset('soccer.n.01')\n",
        "--------------------\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "sALaMxeJTGZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex5[6pt]: Vector-based Lesk\n",
        "\n",
        "The simple Lesk algorith uses the size of the word overlap between the context and the synset gloss to predict the synset. Here we ask you to use vector (cosine) similarity instead of the size of overlap. In sapCy is very simple to check vector similarity between two spaCy's tokens/spans/docs. But this also means that we need to process glosses of relevant synsets with spaCy.  \n",
        "To make things relatively efficient, you can first extract all possibel glosses of target words of the data and process them with a singel `.pipe()` run of spaCy. It is up to you what will be gloss of teh synset, only examples, definitions, or both. Note that you can give several sentences as a singel string for processing to spaCy.  \n",
        "\n",
        "After processing all relevant glosses, one needs to keep processed glosses related to their corresponding synsets. With the help of this, then you can easily retrieve processed glosses when checking similarity to the context of a target word. \n",
        "\n",
        "Read about Vector similarity in spaCy in [sec. 8](https://course.spacy.io/en/chapter2). More about the spaCy's vectors can be found [here](https://spacy.io/api/vectors)."
      ],
      "metadata": {
        "id": "Axwpj85HjpLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "################################## EXERCISE 5 ##################################\n",
        "################################################################################\n",
        "\n",
        "def vector_lesk_sense(data, docs_data):\n",
        "    \"\"\" Takes data and docs_data, and return a list of dictionaries\n",
        "        {'x': synset_of_x, 'y': synset_of_y } where synset_of_x/y is \n",
        "        the sense of x/y in the context_x/y detecting by Lesk-like algorithm,\n",
        "        which selects a sense based on the size of the overlap between the\n",
        "        context and the definition and/or examples of the possible synsets.\n",
        "        Note that pos tag of x/y is retrieved from docs_data and used\n",
        "        to restric the possible senses for a word.\n",
        "        The order in the returned list follows the orders in data and docs_data.\n",
        "    \"\"\"\n",
        "\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "    lijst = []\n",
        "    wordx = []\n",
        "    wordy = []\n",
        "    posx = []\n",
        "    posy = []\n",
        "\n",
        "    synset_of_x = []\n",
        "    synset_of_y = []\n",
        "\n",
        "    for line in data:\n",
        "      wordx.append(line['x'][0])\n",
        "      wordy.append(line['y'][0])\n",
        "\n",
        "    for line in docs_data:\n",
        "      xpos = line['x'][0]\n",
        "      if xpos == 'NOUN':\n",
        "        posx.append('n')\n",
        "      elif xpos == 'VERB':\n",
        "        posx.append('v')\n",
        "      elif xpos == 'ADJ':\n",
        "        posx.append('a')\n",
        "      else:\n",
        "        posx.append('n')\n",
        "    \n",
        "      ypos = line['y'][0]\n",
        "      if ypos == 'NOUN':\n",
        "        posy.append('n')\n",
        "      elif ypos == 'VERB':\n",
        "        posy.append('v')\n",
        "      elif ypos == 'ADJ':\n",
        "        posy.append('a')\n",
        "      else:\n",
        "        posy.append('n') \n",
        "\n",
        "    ####### process the synset definitions with the model (takes ~1m) ################\n",
        "    synset_x_defs = []\n",
        "    for i in range(len(wordx)):\n",
        "      glossesstring = \"\"\n",
        "      for synset in wn.synsets(wordx[i], pos=posx[i]):\n",
        "        glossesstring += f\" {synset.definition()}.\"\n",
        "      synset_x_defs.append(glossesstring[1:])\n",
        "\n",
        "    synset_y_defs = []\n",
        "    for i in range(len(wordy)):\n",
        "      glossesstring = \"\"\n",
        "      for synset in wn.synsets(wordy[i], pos=posy[i]):\n",
        "        glossesstring += f\" {synset.definition()}.\"\n",
        "      synset_y_defs.append(glossesstring[1:])\n",
        "\n",
        "    \n",
        "    doc_x_def = list(nlp.pipe(synset_x_defs))\n",
        "    doc_y_def = list(nlp.pipe(synset_y_defs))\n",
        "    \n",
        "    #################################### get the highest scoring synset for x ########################################################\n",
        "\n",
        "    i = 0\n",
        "    for line in data:\n",
        "      synsets = []\n",
        "      # if the target word has no synsets, the best synset is None\n",
        "      if wn.synsets(wordx[i], pos=posx[i]) == []:\n",
        "        synset_of_x.append(None)\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "      # if the target word has 1 synset, the best synset is that synset\n",
        "      elif len(wn.synsets(wordx[i], pos=posx[i])) == 1:\n",
        "        synset_of_x.append(wn.synsets(wordx[i], pos=posx[i])[0])\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "      # if the target word has more than 1 synset, the best synset is the one with the highest similarity to the sentence\n",
        "      else:\n",
        "        for synset in wn.synsets(wordx[i], pos=posx[i]):\n",
        "          synsets.append(synset)\n",
        "\n",
        "      similarities = []\n",
        "      doc_x_glosses = doc_x_def[i]\n",
        "      synset_def = []\n",
        "      sim_def = []\n",
        "      j = 0\n",
        "\n",
        "      tempgloss = None\n",
        "      for gloss in doc_x_glosses.sents:\n",
        "        # if the gloss does not end with a '.' then add the next gloss (this is because the .sents method also splits the sentence on ')' and in at least 1 case that was a problem)\n",
        "        if gloss.text.split()[-1][-1] != '.':\n",
        "          tempgloss = gloss\n",
        "          continue\n",
        "        #if tempgloss is not empty add the tempgloss to the current gloss to form 1 sentence again.\n",
        "        if tempgloss != None:\n",
        "          gloss = spacy.tokens.Span(tempgloss.doc, tempgloss.start, gloss.end, label=tempgloss.label)\n",
        "\n",
        "        # synset_def = [(a synset of word, their gloss)]\n",
        "        synset_def.append((synsets[j], gloss))\n",
        "        \n",
        "        # if the similarity is empty then it has no best synset\n",
        "        if gloss.similarity(nlp(line['x'][1])) == []:\n",
        "            sim_def.append(None, gloss)\n",
        "        # else add (similarity score, that gloss) to sim_def list\n",
        "        else:\n",
        "          sim_def.append((gloss.similarity(nlp(line['x'][1])), gloss))\n",
        "        \n",
        "        # empty tempgloss\n",
        "        tempgloss = None\n",
        "\n",
        "        j += 1\n",
        "\n",
        "      # get the highest similarity and their gloss\n",
        "      highscore = (0, '')\n",
        "      for sim in sim_def:\n",
        "        if sim[0] > highscore[0]:\n",
        "          highscore = sim\n",
        "\n",
        "      for synset in synset_def:\n",
        "        # if there was no highscore (or the similarity was negative(which did occur sometimes)) then get the simple lesk data of that word\n",
        "        if highscore[0] == 0:\n",
        "          synset_of_x.append(SIMPLE_LESK_data[i]['x'])\n",
        "          break\n",
        "\n",
        "        # else get the highest scoring synset\n",
        "        else:\n",
        "          if highscore[1] == synset[1]:\n",
        "            synset_of_x.append(synset[0])\n",
        "\n",
        "      i += 1\n",
        "\n",
        "    ####################################### get the highest scoring synset for y ############################################################\n",
        "\n",
        "    i = 0\n",
        "    for line in data:\n",
        "      if (i % 100) == 0:\n",
        "        print(i)\n",
        "\n",
        "      synsets = []\n",
        "      # if the target word has no synsets, the best synset is None\n",
        "      if wn.synsets(wordy[i], pos=posy[i]) == []:\n",
        "        synset_of_y.append(None)\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "      # if the target word has 1 synset, the best synset is that synset\n",
        "      elif len(wn.synsets(wordy[i], pos=posy[i])) == 1:\n",
        "        synset_of_y.append(wn.synsets(wordy[i], pos=posy[i])[0])\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "      # if the target word has more than 1 synset, the best synset is the one with the highest similarity to the sentence\n",
        "      else:\n",
        "        for synset in wn.synsets(wordy[i], pos=posy[i]):\n",
        "          synsets.append(synset)\n",
        "\n",
        "      similarities = []\n",
        "      doc_y_glosses = doc_y_def[i]\n",
        "\n",
        "      synset_def = []\n",
        "      sim_def = []\n",
        "      j = 0\n",
        "      tempgloss = None\n",
        "      for gloss in doc_y_glosses.sents:\n",
        "        # if the gloss does not end with a '.' then add the next gloss (this is because the .sents method also splits the sentence on ')' and in at least 1 case that was a problem)\n",
        "        if gloss.text.split()[-1][-1] != '.':\n",
        "          tempgloss = gloss\n",
        "          continue\n",
        "        #if tempgloss is not empty add the tempgloss to the current gloss to form 1 sentence again.\n",
        "        if tempgloss != None:\n",
        "          gloss = spacy.tokens.Span(tempgloss.doc, tempgloss.start, gloss.end, label=tempgloss.label)\n",
        "\n",
        "        # synset_def = [(a synset of word, their gloss)]\n",
        "        synset_def.append((synsets[j], gloss))\n",
        "\n",
        "        # if the similarity is empty then it has no best synset\n",
        "        if gloss.similarity(nlp(line['y'][1])) == []:\n",
        "            sim_def.append(None, gloss)\n",
        "\n",
        "        # else add (similarity score, that gloss) to sim_def list\n",
        "        else:\n",
        "          sim_def.append((gloss.similarity(nlp(line['y'][1])), gloss))\n",
        "        tempgloss = None\n",
        "\n",
        "        j += 1\n",
        "\n",
        "      # get the highest similarity and their gloss\n",
        "      highscore = (0, '')\n",
        "      for sim in sim_def:\n",
        "        if sim[0] > highscore[0]:\n",
        "          highscore = sim\n",
        "\n",
        "      for synset in synset_def:\n",
        "        # if there was no highscore (or the similarity was negative(which did occur sometimes)) then get the simple lesk data of that word\n",
        "        if highscore[0] == 0:\n",
        "          synset_of_y.append(SIMPLE_LESK_data[i]['y'])\n",
        "          break\n",
        "\n",
        "        # else get the highest scoring synset\n",
        "        else:\n",
        "          if highscore[1] == synset[1]:\n",
        "            synset_of_y.append(synset[0])\n",
        "\n",
        "      i += 1\n",
        "################################################################################################################\n",
        "\n",
        "    for i in range(len(synset_of_x)):\n",
        "      lijst.append({'x': synset_of_x[i], 'y': synset_of_y[i]})\n",
        "    return lijst"
      ],
      "metadata": {
        "id": "ghPYMwpBeTVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if efficiently implemented, takes <20sec\n",
        "\n",
        "### We're terribly sorry, our function does work but it takes ~15min. However it does give us accurate data.\n",
        "\n",
        "VEC_LESK_data = vector_lesk_sense(data, docs_data)"
      ],
      "metadata": {
        "id": "81sS2U_DW23O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd29f97a-b46e-423d-93af-566f7d2a7ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nu klaar met pipes, door naar doc_x\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "nu klaar met doc_x. door naar doc_y\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "nu klaar met doc_y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST EX5 \n",
        "# These are the same data samples as the ones above.\n",
        "# compare sense predictions from this to the previous function(s) and find the difference\n",
        "# IMPORTANT: depending on certain choice points, you might not get exactly the same\n",
        "# output as below and that's fine. \n",
        "for i in [628, 766, 3338]:\n",
        "    for xy in 'xy':\n",
        "        print(data[i][xy][:2])\n",
        "        print(docs_data[i][xy])\n",
        "        print(VEC_LESK_data[i][xy])\n",
        "    print(f\"{'':-^20}\")"
      ],
      "metadata": {
        "id": "8QXNvwu3kR3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59a924c-db24-4b60-aa12-1d1c85568ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('sit', 'In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.')\n",
            "('NOUN', In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.)\n",
            "None\n",
            "('stand', 'It was worth my while to try to stand up and punch with him.')\n",
            "('VERB', It was worth my while to try to stand up and punch with him.)\n",
            "Synset('digest.v.03')\n",
            "--------------------\n",
            "('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.')\n",
            "('NOUN', Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.)\n",
            "Synset('family.n.04')\n",
            "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.')\n",
            "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
            "Synset('child.n.01')\n",
            "--------------------\n",
            "('goal', 'Scientific goals.')\n",
            "('NOUN', Scientific goals.)\n",
            "Synset('goal.n.01')\n",
            "('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\")\n",
            "('NOUN', Fans of the Netherlands' soccer team were wildly celebrating too.)\n",
            "Synset('soccer.n.01')\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "('sit', 'In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.')\n",
        "('NOUN', In West Bengal, the ruling Left Front organised sit-ins before the offices of oil PSUs.)\n",
        "None\n",
        "('stand', 'It was worth my while to try to stand up and punch with him.')\n",
        "('VERB', It was worth my while to try to stand up and punch with him.)\n",
        "Synset('digest.v.03')\n",
        "--------------------\n",
        "('family', 'Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.')\n",
        "('NOUN', Father Yus Mawengkang, a Catholic priest in Papua, said the family had been transported to the island on fishing boats and hoped that they would be collected by Australian authorities.)\n",
        "Synset('family.n.08')\n",
        "('child', 'He is survived by three children, along with grandchildren and great-grandchildren.')\n",
        "('NOUN', He is survived by three children, along with grandchildren and great-grandchildren.)\n",
        "Synset('child.n.03')\n",
        "--------------------\n",
        "('goal', 'Scientific goals.')\n",
        "('NOUN', Scientific goals.)\n",
        "Synset('goal.n.04')\n",
        "('soccer', \"Fans of the Netherlands' soccer team were wildly celebrating too.\")\n",
        "('NOUN', Fans of the Netherlands' soccer team were wildly celebrating too.)\n",
        "Synset('soccer.n.01')\n",
        "--------------------\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "k5yC-MVdVUZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex6[6pt]: Mapping relations\n",
        "\n",
        "To relate the word sense disambiguation to the task of predicting contextual lexical relation, we need to have a function that predicts one of the six lexical relations between two synsets. Based on the locations of the synsets in the WordNet, give a reasonable lexical relation between the synsets. For example, `forward_entailment`, `reverse_entailment`, and `equivalence` can be defined in terms of WordNet's hyponym/hypernym relations (see the note about the hypernymy/hyponymy relations below). `alternation` can be defined in terms of [co-hyponymy](https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy#Co-hyponyms). `other-related` can be defined based on other WordNet relations. One can also try to use `similar_tos()` relation which stands for `similar to` for adjectives."
      ],
      "metadata": {
        "id": "mnshCkT4g8DA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For using the hypernymy/hyponymy relation from WordNet, **you need too use its transitive version**.  \n",
        "\n",
        "The hypernymy/hyponymy relation in WordNet doesn't come with transitivity closure. For example, `dog` has a sense `dog.n.01 (a member of the genus Canis ...)` and it is more specific than `animal.n.01 (a living organism ...)`, but this relation cannot be captured with `wn.synset('dog.n.01').hypernyms()` because it lists the immediate hypernyms: `canine.n.02'` and `domestic_animal.n.01`.  \n",
        "The real picture in WordNet is the following: `dog.n.01` < `domestic_animal.n.01` < `animal.n.01` OR `dog.n.01` < `canine.02` < `carnivore.n.01` < ... < `chordate.n.01` < `animal.n.01`, where x < y denotes that x is more specific than y, i.e., x is a hyponym of y, i.e., y is a hypernym of x.  \n",
        "We would like to capture the transitivity closure of the hypernymy relation. The NLTK's [howto](https://www.nltk.org/howto/wordnet.html) about WordNet will help you in this.  "
      ],
      "metadata": {
        "id": "NvP4JFOPVBQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides defining `lex_rel`, explain and motivate your WordNet-based definitions of lexical relations. Giving examples will help the explanation.\n",
        "\n",
        "<font color=\"red\">█████ MOTIVATION █████</font>\n",
        "\n",
        "TYPE YOUR MOTIVATION HERE (don't delete the heaader)\n",
        "\n",
        "Independent: \n",
        "if ss1 or ss2 are None.\n",
        "\n",
        "Equivalence: If ss1 is equal to ss2, they are equal.\n",
        "\n",
        "Forward_entailment:\n",
        "If ss1 entails ss2, ss1 is a hypernym of ss2.\n",
        "\n",
        "Reverse_entailment:\n",
        "If ss2 entails ss1, ss1 is a hyponym of ss2.\n",
        "\n",
        "Alternation: ss1 and ss2 share a common hypernym.\n",
        "\n",
        "Other-related: The rest."
      ],
      "metadata": {
        "id": "INx550royB7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "################################## EXERCISE 6 ##################################\n",
        "################################################################################\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='nltk')\n",
        "\n",
        "def lex_rel(ss1, ss2):\n",
        "    \"\"\" Takes two synsets and based on wordnet it outputs one of the following six\n",
        "        relations: 'independent', 'equivalence', 'forward_entailment',\n",
        "                   'reverse_entailment', 'alternation', 'other-related'\n",
        "        if one of the sensets is None, it returns 'independent'.  \n",
        "    \"\"\"\n",
        "    # Check for None synsets (independent)\n",
        "    if ss1 is None or ss2 is None:\n",
        "      return 'independent'\n",
        "    \n",
        "    ss1hypers = list(ss1.closure(lambda s: s.hypernyms()))\n",
        "    ss2hypers = list(ss2.closure(lambda s: s.hypernyms()))\n",
        "    # Check for exact match (equivalence)\n",
        "    if ss1 == ss2:\n",
        "      return 'equivalence'\n",
        "\n",
        "    # Check for forward entailment (ss1 is a hypernym of ss2)\n",
        "    if ss2 in ss1hypers:\n",
        "      return 'forward_entailment'\n",
        "\n",
        "    # Check for reverse entailment (ss2 is a hypernym of ss1)\n",
        "    if ss1 in ss2hypers:\n",
        "      return 'reverse_entailment'\n",
        "\n",
        "    # Check for alternation (ss1 and ss2 share a common hypernym)\n",
        "    set1 = set(ss1hypers)\n",
        "    set2 = set(ss2hypers)\n",
        "    if len(set1.intersection(set2)) != 0:\n",
        "      return 'alternation'\n",
        "\n",
        "    # If none of the conditions are met, return 'other-related'\n",
        "    return 'other-related'"
      ],
      "metadata": {
        "id": "kcdO37t5g8LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting all together\n",
        "\n",
        "Now we are putting together the various WSD functions and the definition of lexical relations between synsets based on WordNet."
      ],
      "metadata": {
        "id": "vEH9lRpIiJBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in-context semantic relation classifier\n",
        "def contextual_lex_rel(data, docs_data, WSD_OR_OUT):\n",
        "    \"\"\" In addition to the raw data and processed data, it takes \n",
        "        the WSD function (most_frequent_sense, simple_lesk_sense, vector_lesk_sense)\n",
        "        or its output and \n",
        "        Returns a list of predictions, i.e. one of teh six relations\n",
        "    \"\"\" \n",
        "    # this construction is also called ternary operator\n",
        "    # https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator\n",
        "    wsd_data = WSD_OR_OUT if isinstance(WSD_OR_OUT, list) else WSD_OR_OUT(data, docs_data)\n",
        "    # predciting relations for each data sample\n",
        "    predicted_rels = [ lex_rel(d['x'], d['y']) for d in wsd_data ]\n",
        "    return predicted_rels"
      ],
      "metadata": {
        "id": "Ger8gNEYhTIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST: the number of predictions should be the size of data\n",
        "mfs_pred = contextual_lex_rel(data, docs_data, MFS_data)\n",
        "print(f\"Num of predictions = {len(mfs_pred)}\")\n",
        "# the predictions should only include at most six possible relations\n",
        "print(f\"A set of predictions = {set(mfs_pred)}\")"
      ],
      "metadata": {
        "id": "QyrMxO4Z07qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74778cd-47fb-4c62-809f-ed5a7fbfe308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of predictions = 3404\n",
            "A set of predictions = {'alternation', 'reverse_entailment', 'forward_entailment', 'independent', 'other-related', 'equivalence'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Num of predictions = 3404\n",
        "A set of predictions = {'equivalence', 'alternation', 'reverse_entailment', 'other-related', 'independent', 'forward_entailment'}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BhaHlkU9WCO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best performance\n",
        "\n",
        "The code displays performance of all combinations of wsd components and the lexical relation definition. \n",
        "\n",
        "<font color=\"red\">The groups of the top three perfroming systems will get additional bonus points (taking into account their positions `{1:5pt, 2:3pt, 3:2pt}`).</font>  \n",
        "Note that most frequent sense (MFS) baseline is usually very good when it comes to word sense disambiguation. So, if your system is not better than the one based on MFS, it's ok. Remember that in general WSD is a hard task, especially when WSD is done wrt WordNet that has so many fine-grained synsets per word."
      ],
      "metadata": {
        "id": "6rGtXtUOkbKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST final system evaluation\n",
        "for wsd, name in zip([MFS_data, SIMPLE_LESK_data, VEC_LESK_data], \n",
        "               \"mfs simple_lesk vector_lesk\".split()):\n",
        "    pred = contextual_lex_rel(data, docs_data, wsd)\n",
        "    acc = evaluate_contextual_lex_rel(pred, data)\n",
        "    print(f\"{name}: {acc}\")"
      ],
      "metadata": {
        "id": "_ZX2H7BokiA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cb57ba-e9a4-48f5-dcb7-b34c4d6f83e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mfs: 0.20593419506462984\n",
            "simple_lesk: 0.15305522914218567\n",
            "vector_lesk: 0.14482961222091656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reasoning [Added]\n",
        "\n",
        "We show how reasoning is done with the natural tableau theorem prover, how certain inference relations are (in)correctly predicted, and how manually proving the lexical knowledge can help to find proofs.  \n",
        "First we need to create LangPro object that knows locaton of LangPro's and SICK files. "
      ],
      "metadata": {
        "id": "Cn8ZuDaluwab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install LangPro for SICK"
      ],
      "metadata": {
        "id": "bZGhsX2c1Ped"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processed SICK\n",
        "\n",
        "We are downloading CCG parsed sentences of [SICK](http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf) (Sentences involving compositional knowledge) dataset. The dataset has been used as a benchmark for natural language inference (aka recognizing textual entailment) [shared task](https://aclanthology.org/S14-2001.pdf). In a nutshell, the dataset has three parts (train, trial, and test) and each part contains inference problems, a pair of sentences annotated with one of the inference relation (entailment, contradiction, or neutral).  \n",
        "Note that we have used train part of the SICK dataset in assignment 1."
      ],
      "metadata": {
        "id": "EfOQdxad1Pef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QutKEyYH1Pei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57416ca-8d2d-43c9-d963-77a36c96d8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-19 17:34:05--  https://naturallogic.pro/_files_/download/SICK4LangPro.zip\n",
            "Resolving naturallogic.pro (naturallogic.pro)... 85.214.116.22\n",
            "Connecting to naturallogic.pro (naturallogic.pro)|85.214.116.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1679211 (1.6M) [application/zip]\n",
            "Saving to: ‘SICK4LangPro.zip’\n",
            "\n",
            "SICK4LangPro.zip    100%[===================>]   1.60M  8.71MB/s    in 0.2s    \n",
            "\n",
            "2023-05-19 17:34:05 (8.71 MB/s) - ‘SICK4LangPro.zip’ saved [1679211/1679211]\n",
            "\n",
            "Archive:  SICK4LangPro.zip\n",
            "  inflating: SICK/SICK_sen.pl        \n",
            "  inflating: SICK/nltk_anno_sen.pl   \n",
            "  inflating: SICK/nltk_cc2016.st.pl  \n",
            "  inflating: SICK/nltk_easyccg.pl    \n",
            "  inflating: SICK/nltk_depccg.trihf.sep.pl  \n"
          ]
        }
      ],
      "source": [
        "# Downloading already tagged and CCG parsed SICK dataset\n",
        "!wget https://naturallogic.pro/_files_/download/SICK4LangPro.zip\n",
        "!unzip SICK4LangPro.zip -d SICK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the current version of prolog is not happy with two consecutive commas, so we are repalcing them accordingly\n",
        "!sed -i \"s/t(,,/t(',',/g\" SICK/nltk_depccg.trihf.sep.pl"
      ],
      "metadata": {
        "id": "AOdPbYZStpkh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7m9acB61Pek"
      },
      "source": [
        "### SWI-Prolog\n",
        "LangPro is written in prolog, so we need to install prolog first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtKceOco1Pel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37d1948-e38a-41c3-8602-7517f73ed9d7"
      },
      "source": [
        "# installing swi-prolog\n",
        "!sudo apt-add-repository ppa:swi-prolog/stable -y\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install swi-prolog"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/114 kB 12%] [Connected to cloud.r\r                                                                               \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 114 kB/114 kB 100%] [Connected to cloud.r\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "\r                                                                               \rGet:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r                                                                               \rHit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "\r                                                                               \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "\r                                                                               \rHit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "\r                                                                               \rHit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:11 http://ppa.launchpad.net/swi-prolog/stable/ubuntu focal InRelease [23.8 kB]\n",
            "Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,344 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,175 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,699 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,049 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,240 kB]\n",
            "Get:18 http://ppa.launchpad.net/swi-prolog/stable/ubuntu focal/main amd64 Packages [1,500 B]\n",
            "Fetched 10.9 MB in 3s (3,839 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/swi-prolog/stable/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  javascript-common libbsd-dev libedit-dev libgmp-dev libgmpxx4ldbl\n",
            "  libjs-jquery libossp-uuid16 swi-prolog-nox swi-prolog-x\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd gmp-doc libgmp10-doc libmpfr-dev uuid prolog-el\n",
            "The following NEW packages will be installed:\n",
            "  javascript-common libbsd-dev libedit-dev libgmp-dev libgmpxx4ldbl\n",
            "  libjs-jquery libossp-uuid16 swi-prolog swi-prolog-nox swi-prolog-x\n",
            "0 upgraded, 10 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 7,603 kB of archives.\n",
            "After this operation, 38.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:2 http://ppa.launchpad.net/swi-prolog/stable/ubuntu focal/main amd64 swi-prolog-nox amd64 9.0.4-1-g99fa726d0-focalppa2 [4,482 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libbsd-dev amd64 0.10.0-1 [164 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libedit-dev amd64 3.1-20191231-1 [106 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgmpxx4ldbl amd64 2:6.2.0+dfsg-4ubuntu0.1 [9,144 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgmp-dev amd64 2:6.2.0+dfsg-4ubuntu0.1 [320 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libjs-jquery all 3.3.1~dfsg-3 [329 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 libossp-uuid16 amd64 1.6.2-1.5build7 [28.4 kB]\n",
            "Get:9 http://ppa.launchpad.net/swi-prolog/stable/ubuntu focal/main amd64 swi-prolog-x amd64 9.0.4-1-g99fa726d0-focalppa2 [2,131 kB]\n",
            "Get:10 http://ppa.launchpad.net/swi-prolog/stable/ubuntu focal/main amd64 swi-prolog amd64 9.0.4-1-g99fa726d0-focalppa2 [27.2 kB]\n",
            "Fetched 7,603 kB in 0s (26.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package javascript-common.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../0-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libbsd-dev:amd64.\n",
            "Preparing to unpack .../1-libbsd-dev_0.10.0-1_amd64.deb ...\n",
            "Unpacking libbsd-dev:amd64 (0.10.0-1) ...\n",
            "Selecting previously unselected package libedit-dev:amd64.\n",
            "Preparing to unpack .../2-libedit-dev_3.1-20191231-1_amd64.deb ...\n",
            "Unpacking libedit-dev:amd64 (3.1-20191231-1) ...\n",
            "Selecting previously unselected package libgmpxx4ldbl:amd64.\n",
            "Preparing to unpack .../3-libgmpxx4ldbl_2%3a6.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgmpxx4ldbl:amd64 (2:6.2.0+dfsg-4ubuntu0.1) ...\n",
            "Selecting previously unselected package libgmp-dev:amd64.\n",
            "Preparing to unpack .../4-libgmp-dev_2%3a6.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgmp-dev:amd64 (2:6.2.0+dfsg-4ubuntu0.1) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../5-libjs-jquery_3.3.1~dfsg-3_all.deb ...\n",
            "Unpacking libjs-jquery (3.3.1~dfsg-3) ...\n",
            "Selecting previously unselected package libossp-uuid16:amd64.\n",
            "Preparing to unpack .../6-libossp-uuid16_1.6.2-1.5build7_amd64.deb ...\n",
            "Unpacking libossp-uuid16:amd64 (1.6.2-1.5build7) ...\n",
            "Selecting previously unselected package swi-prolog-nox.\n",
            "Preparing to unpack .../7-swi-prolog-nox_9.0.4-1-g99fa726d0-focalppa2_amd64.deb ...\n",
            "Unpacking swi-prolog-nox (9.0.4-1-g99fa726d0-focalppa2) ...\n",
            "Selecting previously unselected package swi-prolog-x.\n",
            "Preparing to unpack .../8-swi-prolog-x_9.0.4-1-g99fa726d0-focalppa2_amd64.deb ...\n",
            "Unpacking swi-prolog-x (9.0.4-1-g99fa726d0-focalppa2) ...\n",
            "Selecting previously unselected package swi-prolog.\n",
            "Preparing to unpack .../9-swi-prolog_9.0.4-1-g99fa726d0-focalppa2_amd64.deb ...\n",
            "Unpacking swi-prolog (9.0.4-1-g99fa726d0-focalppa2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up libossp-uuid16:amd64 (1.6.2-1.5build7) ...\n",
            "Setting up libgmpxx4ldbl:amd64 (2:6.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.3.1~dfsg-3) ...\n",
            "Setting up libbsd-dev:amd64 (0.10.0-1) ...\n",
            "Setting up libgmp-dev:amd64 (2:6.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up libedit-dev:amd64 (3.1-20191231-1) ...\n",
            "Setting up swi-prolog-nox (9.0.4-1-g99fa726d0-focalppa2) ...\n",
            "update-alternatives: using /usr/bin/swipl to provide /usr/bin/prolog (prolog) in auto mode\n",
            "Setting up swi-prolog-x (9.0.4-1-g99fa726d0-focalppa2) ...\n",
            "Setting up swi-prolog (9.0.4-1-g99fa726d0-focalppa2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-mMuF0G1Pen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7721a9d3-bceb-41cc-d393-af6b0f046a00"
      },
      "source": [
        "#TEST: checking version of installed swi-prolog\n",
        "!swipl --version"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SWI-Prolog version 9.0.4 for x86_64-linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XSL transformation"
      ],
      "metadata": {
        "id": "m0lmKN961Pep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need xsltproc to apply xsl transformations to xml files\n",
        "# to obtain fancy tableau proves in .html format\n",
        "!sudo apt install xsltproc"
      ],
      "metadata": {
        "id": "_8QY9e3L1Peq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3253ba-5262-494b-bd1e-d6ba939e63bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xsltproc\n",
            "0 upgraded, 1 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 14.3 kB of archives.\n",
            "After this operation, 164 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xsltproc amd64 1.1.34-4ubuntu0.20.04.1 [14.3 kB]\n",
            "Fetched 14.3 kB in 0s (317 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package xsltproc.\n",
            "(Reading database ... 125060 files and directories currently installed.)\n",
            "Preparing to unpack .../xsltproc_1.1.34-4ubuntu0.20.04.1_amd64.deb ...\n",
            "Unpacking xsltproc (1.1.34-4ubuntu0.20.04.1) ...\n",
            "Setting up xsltproc (1.1.34-4ubuntu0.20.04.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST: check that xsltproc is here\n",
        "!xsltproc -V"
      ],
      "metadata": {
        "id": "SpNR87sb1Per",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa488188-571a-4bd0-b11a-0c91a22811ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using libxml 20910, libxslt 10134 and libexslt 820\n",
            "xsltproc was compiled against libxml 20910, libxslt 10134 and libexslt 820\n",
            "libxslt 10134 was compiled against libxml 20910\n",
            "libexslt 820 was compiled against libxml 20910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2--I4waO1Per"
      },
      "source": [
        "### LangPro\n",
        "\n",
        "Clone LangPro repository and use `x-anno` branch. The LangPro comes with WordNet because we need some lexical knowledge to do interesting inferences in natural language."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cloning LangPro repo\n",
        "!rm -fr LangPro # helps to rerun this cell witthout errors, if recloning needed \n",
        "!git clone --single-branch --branch x-anno https://github.com/kovvalsky/LangPro.git"
      ],
      "metadata": {
        "id": "251cIbbL1Pes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574baab4-7ef5-4b6b-8509-13ae978f92bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LangPro'...\n",
            "remote: Enumerating objects: 2117, done.\u001b[K\n",
            "remote: Counting objects: 100% (199/199), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 2117 (delta 150), reused 156 (delta 135), pack-reused 1918\u001b[K\n",
            "Receiving objects: 100% (2117/2117), 26.26 MiB | 13.56 MiB/s, done.\n",
            "Resolving deltas: 100% (1379/1379), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST: check that LangPro is here\n",
        "!swipl -g \"print_param, halt\" -f LangPro/prolog/main.pl"
      ],
      "metadata": {
        "id": "UqFp7vGT1Pet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68104eb9-62d7-4540-df9d-1ba285e17157"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":- dynamic debMode/1.\n",
            ":- multifile debMode/1.\n",
            "\n",
            "debMode(nil).\n",
            "debMode(ral(400)).\n",
            "debMode(effCr([equi, nonBr, nonProd, nonCons])).\n",
            "debMode(wn_sim).\n",
            "debMode(wn_ant).\n",
            "debMode(wn_der).\n",
            "debMode(aall).\n",
            "debMode(constchk).\n",
            "debMode(parts([trial])).\n",
            "\n",
            ":- dynamic correct_term:debMode/1.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using LangPro\n",
        "\n",
        "LangPro is a tableau-based theorem prover for natural logic. In general, it can take one or multiple premises and a singel hypothesis/conclusion and based on the tableu proofs predict whether the premises(s) entail/contradict/is neutral to the conclusion.  \n",
        "Since we will be dealing with inference problems from SICK (premise-hypothesis pairs), we show how LangPro can be used for SICK."
      ],
      "metadata": {
        "id": "c38N_R6nYxMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in case the utility functions for running langpro were not included\n",
        "from assigntools.M4LP.A2 import show_tableau, LangPro"
      ],
      "metadata": {
        "id": "TE7p-0gx1Peu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a langpro object that needs pointers to LangPro and SICK directories\n",
        "lp = LangPro(\"LangPro\", \"SICK\")"
      ],
      "metadata": {
        "id": "cPVW2cdP1Pev"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can run the prover on a list of SICK problems and let it classify each with inference labels: yes=enatilment, no=contradiction, unknown=neutral. `.nli_prove()` method allows various parameters. Their definitions can be found [here](https://github.com/kovvalsky/assigntools/blob/f0bf6254e115c047f5aa09e06e32b6a5086e9608/M4LP/A2.py#L79). <font color=red>It is important to read the function definition</font>.  \n",
        "When running `.nli_prove()`, it reads the input and calls prolog to run LangPro with the input. Whatever LangPro prints to the standard output is collected and returned as a string. If LangPro errors due to unexpected input, the output string will contain error messages. If everuthing runs fine, `.nli_prove()` returns a string representing logs for proofs of each problem. The pattern of the log is following:  \n",
        "```\n",
        "ProblemID:   [GoldLabel], LangProPrediction, ... tableau proof details (not important)\n",
        "    Premise_of_the_problem\n",
        "    Hypothesis_of_the_problem\n",
        "``` \n",
        "At the end of the log there is a confusion matrix 3x3 with row & columns corresponding to SICK labels and LangPro's predictions, respectively."
      ],
      "metadata": {
        "id": "JYZ30XOv1Pew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prove all the problems whose IDs are in 1-200 interval, whose gold labels\n",
        "# are either 'yes' or 'no', and print the problem sentences when printing a report.\n",
        "# Note that the problems by default are picked from train & trial parts of SICK\n",
        "# parts=['train','trial'], and it uses max 50 inference rule application per tableau. \n",
        "print(lp.nli_prove('1-200', print_prob=True, labels=['yes', 'no']))\n",
        "\n",
        "# proving problems 10, 100, 1000 from train. 10 will be skipped as only 100 & 1000 are in train.\n",
        "# print(lp.nli_prove([10,100,1000], print_prob=True, parts=['train']))"
      ],
      "metadata": {
        "id": "TfeWYEkc1Pex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd59efda-c232-43c4-9243-1e4ee0f7614b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   3:     [yes], unknown,    open, 'Lim',76    XP: []\n",
            "      The young boys are playing outdoors and the man is smiling nearby\n",
            "      The kids are playing outdoors near a man with a smile\n",
            "  30:     [yes], unknown,    open, 'Ter',56    XP: []\n",
            "      A man with a jersey is dunking the ball at a basketball game\n",
            "      The ball is being dunked by a man with a jersey at a basketball game\n",
            "  42:      [no],      no,  closed, 'Ter',6     XP: []\n",
            "      Two people are kickboxing and spectators are not watching\n",
            "      Two people are kickboxing and spectators are watching\n",
            "  44:     [yes], unknown,    open, 'Lim',69    XP: []\n",
            "      Two young women are sparring in a kickboxing fight\n",
            "      Two women are sparring in a kickboxing match\n",
            "  55:     [yes],     yes,  closed, 'Ter',2     XP: [isa(boy,kid)]\n",
            "      Three boys are jumping in the leaves\n",
            "      Three kids are jumping in the leaves\n",
            "  77:     [yes], unknown,    open, 'Lim',100   XP: []\n",
            "      People wearing costumes are gathering in a forest and are looking in the same direction\n",
            "      Masked people are looking in the same direction in a forest\n",
            "  87:     [yes], unknown,    open, 'Ter',13    XP: []\n",
            "      A lone biker is jumping in the air\n",
            "      A biker is jumping in the air, alone\n",
            "  88:      [no],      no,  closed, 'Ter',9     XP: [int(lone)]\n",
            "      There is no biker jumping in the air\n",
            "      A lone biker is jumping in the air\n",
            "  90:      [no], unknown,    open, 'Ter',77    XP: []\n",
            "      A man is jumping into an empty pool\n",
            "      A man is jumping into a full pool\n",
            "  98:     [yes],     yes,  closed, 'Ter',1     XP: [isa(child,kid),isa(kid,child)]\n",
            "      Four kids are doing backbends in the park\n",
            "      Four children are doing backbends in the park\n",
            " 100:     [yes], unknown,    open, 'Ter',55    XP: []\n",
            "      Four girls are doing backbends and playing in the garden\n",
            "      Four girls are doing backbends and playing outdoors\n",
            " 107:     [yes],     yes,  closed, 'Ter',12    XP: [der(play,player)]\n",
            "      A man who is playing is running with the ball in his hands\n",
            "      A player is running with the ball\n",
            " 122:      [no], unknown,    open, 'Lim',59    XP: []\n",
            "      Five kids are standing close together and one kid has a gun\n",
            "      Five kids are standing close together and none of the kids has a gun\n",
            " 129:     [yes],     yes,  closed, 'Ter',2     XP: [isa(old man,man)]\n",
            "      An old man is sitting in a field\n",
            "      A man is sitting in a field\n",
            " 140:     [yes],     yes,  closed, 'Ter',16    XP: []\n",
            "      The current is being ridden by a group of friends in a raft\n",
            "      A group of friends are riding the current in a raft\n",
            " 141:      [no], unknown,    open, 'Ter',22    XP: []\n",
            "      A group of friends are riding the current in a raft\n",
            "      A group is not riding the current in a raft\n",
            " 150:      [no],      no,  closed, 'Ter',8     XP: [isa(a,the),isa(the,a)]\n",
            "      A deer is jumping over a fence\n",
            "      A deer isn't jumping over the fence\n",
            " 161:      [no],      no,  closed, 'Ter',7     XP: [int(several),isa(a,the),isa(the,a)]\n",
            "      Several people are in front of a colorful building\n",
            "      Nobody is in front of the colorful building\n",
            " 164:     [yes], unknown,    open, 'Lim',86    XP: []\n",
            "      People are walking outside the building that has several murals on it\n",
            "      Several people are in front of a colorful building\n",
            " 192:      [no],      no,  closed, 'Ter',10    XP: [int(white)]\n",
            "      A motorcycle rider is standing up on the seat of a white motorcycle\n",
            "      No motorcycle rider is standing up on the seat of a motorcycle\n",
            " 194:      [no],      no,  closed, 'Ter',9     XP: []\n",
            "      Nobody is on a motorcycle and is standing on the seat\n",
            "      Someone is on a black and white motorcycle and is standing on the seat\n",
            " 200:     [yes],     yes,  closed, 'Ter',11    XP: []\n",
            "      A motorcyclist is riding a motorbike dangerously along a roadway\n",
            "      A motorcyclist is riding a motorbike along a roadway\n",
            "   4:      [no],      no,  closed, 'Ter',17    XP: [int(young),isa(boy,man)]\n",
            "      The young boys are playing outdoors and the man is smiling nearby\n",
            "      There is no boy playing outdoors and there is no man smiling\n",
            "------------------------------------------------------ \n",
            " Gold\\Prover       YES       NO       UNK       DEF\n",
            "------------------------------------------------------ \n",
            " ENTAILMENT:        6        0        7 (4)      0 \n",
            "------------------------------------------------------ \n",
            " CONTRADICTION:     0        7        3 (1)      0 \n",
            "------------------------------------------------------ \n",
            " NEUTRAL:           0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            "Total #problems:  23\n",
            "Accuracy (pure):  0.56522    (0.56522)\n",
            "Precision:        1.00000\n",
            "Recall (pure):    0.56522    (0.56522)\n",
            "------------ STATS -------------\n",
            "Total #clTabperPrb:            13\n",
            "Total #ruleApps for clTab:     110\n",
            "Average #ruleApps for clTab:   8.46154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that problems with IDs 1 and 2 are in the test part of SICK, that's why they are missing (by default only train and trial parts are picked).  \n",
        "From the output we see that problem-150 is correctly classified as contradiction, i.e., \"no\" by the prover. Let's view the tableau that is responsible for the proof. To generate tableaux for a particular problem, we use `.tableau_prove()` method. Unlike `.nli_prove()`, this method additionally builds tableau proofs in a tree shape for easy exploring of the proofs. In general, there can be 4 tableaux built per problem: a combination of processing aligned/non-aligned terms and entailment/contradiction checks. By default, `.tableau_prove()` builds 2 tableaux for aligned terms for efficiency. Definitions of `.tableau_prove()` arguments can be found [here](https://github.com/kovvalsky/assigntools/blob/f0bf6254e115c047f5aa09e06e32b6a5086e9608/M4LP/A2.py#L118). <font color=red>It is important to read the function definition</font>.  \n",
        "The usage of aligned terms is a computational trick LangPro uses to overcome inconsistent gold labeling of SICK. For example, problem-150 comes with gold label contradiction, assuming that \"a deer\" in both sentences are the same. Strictly logically speaking problem-150 is not contradiction in the same was as $\\exists x.P(x)$ and $\\exists x.\\neg P(x)$ not being contradiction in FOL. To predict problems like 150 as contrdiction, aligning terms treat shared pharses between premise and hypothesis as constants terms, e.g. a compund term `a@deer` becomes a constant term `'a@deer'` and behaves as a proper name, like `john` or `mary`.   "
      ],
      "metadata": {
        "id": "fshUEJWQ1Pey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting tableaux for problem id=150:\n",
        "# premise:      A deer is jumping over a fence\n",
        "# conclusion:   A deer isn't jumping over the fence\n",
        "out, mode2html = lp.tableau_prove(150) # by default align=\"align\", ral=50\n",
        "# viewing the tableau that is built on aligned terms and proves contradiction\n",
        "show_tableau(mode2html[('align','no')])\n",
        "# in this case a key [('no_align','no')] would throw an error as mode2html \n",
        "# is built with align=\"align\" and it doesn't contain a tableau for non-aligned terms"
      ],
      "metadata": {
        "id": "m7qlXl_M1Pez",
        "colab": {
          "resources": {
            "http://localhost:8080/css/tableau.css": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "0eeca724-494a-44a2-c321-aa7a317b040f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".tableau {\n",
              "\ttext-align:center;\n",
              "\tdisplay:block;\n",
              "\t/*background-color: rgb(250, 230, 180);*/\n",
              "\tcolor: #000;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              ".tree {\n",
              "  vertical-align: top;\n",
              "\tdisplay: inline-block;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\tpadding-top: 15px; /*level distance*/\n",
              "\twhite-space: nowrap;\n",
              "\t/*border: 1px solid red;*/\n",
              "}\n",
              "\n",
              "\n",
              "/**************** DRAWING LINES*****************/\n",
              "/*We will use ::before and ::after to draw the connectors*/\n",
              ".tree::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; right: 50%;\n",
              "}\n",
              ".tree::after{\n",
              "    content: '';\n",
              "    position: absolute; top: 0;\n",
              "    border-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; left: 50%;\n",
              "}\n",
              "/*We need to remove left-right connectors from elements without\n",
              "any siblings*/\n",
              ".tree:only-of-type::after, .tree:only-of-type::before {\n",
              "    display:none;\n",
              "}\n",
              "\n",
              "/*Remove space from the top of single children*/\n",
              ".tree:only-child{ padding-top: 0;}\n",
              "\n",
              "/*Remove left connector from first child and\n",
              "right connector from last child*/\n",
              ".tree:first-child::before, .tree:last-child::after{\n",
              "\tborder: 0 none;\n",
              "}\n",
              "/*Adding back the vertical connector to the last nodes*/\n",
              ".tree:last-child::before{\n",
              "\tborder-right: 2px solid #aaa;\n",
              "\tborder-top-right-radius: 10px;\n",
              "}\n",
              "\n",
              ".tree:first-child::after{\n",
              "\tborder-top-left-radius: 10px;\n",
              "\tborder-left: 2px solid #aaa;\n",
              "}\n",
              "\n",
              "/*Time to add downward connectors from parents*/\n",
              ".subTrees::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-left: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px;\n",
              "\tleft: 50%;\n",
              "}\n",
              "\n",
              ".subTrees {\n",
              "    /*border: 1px solid green;*/\n",
              "    padding-top: 15px;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\twhite-space: nowrap;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/*********** NODE formatting ***********/\n",
              ".node {\n",
              "    display:inline-block;\n",
              "\tborder-radius: 3px; border: 1px solid #aaa;\n",
              "}\n",
              ".node_id {\n",
              "    font-family:\"Courier New\", Courier, monospace; color: #fff;\n",
              "    padding-left: 2px; background-color: #555;\n",
              "    border-radius: 3px 0px 0px 3px;\n",
              "}\n",
              ".modList, .argList, .llf {\n",
              "\tfont-family:\"Courier New\", Courier, monospace;\n",
              "\tborder-left: 2px solid #aaa; padding: 0px 3px 0px 3px;\n",
              "    margin-left: -4px;\n",
              "}\n",
              ".true >  .llf{ background-color:rgb(210,250,200); }\n",
              ".false > .llf{ background-color:rgb(250,210,200); }\n",
              ".modList{background-color:rgb(210,200,250);}\n",
              ".argList{background-color:rgb(250,230,150);}\n",
              "\n",
              ".source > span.source {\n",
              "    display: inline;\n",
              "\tfont-size:85%; color: #fff;\n",
              "\tborder: 1px solid #aaa;\n",
              "\tpadding: 0px 2px 2px 2px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 5px 5px;\n",
              "\tbackground-color:#555;\n",
              "}\n",
              "\n",
              "/************* Open branch and Closure ********************/\n",
              ".open_branch > i.fa.fa-unlock{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 200%;\n",
              "   padding-left: 4px; display: block;\n",
              "}\n",
              "\n",
              "div.open_branch {\n",
              "    font-family: \"Courier New\", Courier, monospace;\n",
              "    color: #999; font-weight: bold;\n",
              "}\n",
              "\n",
              ".closure > i.fa.fa-times-circle{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 170%;\n",
              "   padding-left: 4px;\n",
              "}\n",
              ".closer{\n",
              "  font-size:80%;\n",
              "  color: #aaa;\n",
              "  font-weight: bold;\n",
              "  border: 1px solid #aaa;\n",
              "  padding: 0px 3px 3px 3px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 7px 7px;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/******** Styling the problem ************/\n",
              "\n",
              ".problem {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              "    margin-left: auto;\n",
              "    margin-right: auto;\n",
              "\tpadding-bottom: 20px;\n",
              "}\n",
              "\n",
              ".premise {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              " \tbackground-color:rgb(210,250,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "\n",
              ".conclusion {\n",
              "\tdisplay:block;\n",
              "    text-align:center;\n",
              "\tborder-top: 3px solid #aaa;\n",
              "\tbackground-color:rgb(250,210,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/tableau.css\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css\">\n",
              "<title>Tableau</title>\n",
              "</head>\n",
              "<body><div class=\"tableau\">\n",
              "<div class=\"problem\">\n",
              "<div class=\"premise\">A deer is jumping over a fence</div>\n",
              "<div class=\"conclusion\">? A deer isn't jumping over the fence</div>\n",
              "</div>\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">1</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_356,a@fence@(λ_512,over@_512@jump@_356))@'a@deer'</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">2</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">not@(be@(λ_1016,the@fence@(λ_512,over@_512@jump@_1016)))@'a@deer'</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">3</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">not@(be@(λ_1016,the@fence@(λ_512,over@_512@jump@_1016)))</span>\n",
              "<span class=\"argList\">'a@deer'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_arg[2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">4</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_1016,the@fence@(λ_512,over@_512@jump@_1016))</span>\n",
              "<span class=\"argList\">'a@deer'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">neg_not[3]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">5</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">(λ_1016,the@fence@(λ_512,over@_512@jump@_1016))</span>\n",
              "<span class=\"argList\">'a@deer'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[4]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">6</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">the@fence@(λ_512,over@_512@jump@'a@deer')</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[5]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">7</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_356,a@fence@(λ_512,over@_512@jump@_356))</span>\n",
              "<span class=\"argList\">'a@deer'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_arg[1]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">8</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">(λ_356,a@fence@(λ_512,over@_512@jump@_356))</span>\n",
              "<span class=\"argList\">'a@deer'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[7]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">9</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">a@fence@(λ_512,over@_512@jump@'a@deer')</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[8]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\"></div>\n",
              "<div class=\"closure\">\n",
              "<i class=\"fa fa-times-circle\"></i><div class=\"closer\">\n",
              "<div class=\"closer_rule\">cl_subsumption</div>\n",
              "<div class=\"closer_ids\">[9,6]</div>\n",
              "</div>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></body>\n",
              "</html>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tableau proof for contradiction of problem 150 shows that the tree has a single branch and it is closed. This shows that there is no possible situation that makes the premise and hypothesis of the problem true at the same time (note that the tableau uses aligned terms and \"a deer\" is treated as a constant `'a@deer'`).  \n",
        "But not all problems are correctly classified. For example, problem-44 should have been classified as entailment, instead it is classified as neutral. One of the reasons could be that WordNet doesn't tell the prover that there is a sense of `fight` that is a `match` in its some sense. Let's manually feed the prover with this relation and see if it helps. "
      ],
      "metadata": {
        "id": "LPJxloRo1Pez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out, mode2html = lp.tableau_prove(44, kb=\"isa(fight,match)\")\n",
        "# it is always a good idea to print the log, because if the LangPro errors\n",
        "# this is the only way you can see it. \n",
        "print(out) \n",
        "# you can also feed several relations as \"isa(fight,match), isa(match,fight)\""
      ],
      "metadata": {
        "id": "8XniCiOl1Pe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d809fb5-5ca3-41ec-909d-e11fdbe0237e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  44:     [yes],     yes,  closed, 'Ter',19    XP: [int(kickboxing),int(young),isa(fight,match),isa(young woman,woman)]\n",
            "------------------------------------------------------ \n",
            " Gold\\Prover       YES       NO       UNK       DEF\n",
            "------------------------------------------------------ \n",
            " ENTAILMENT:        1        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " CONTRADICTION:     0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " NEUTRAL:           0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            "Total #problems:  1\n",
            "Accuracy (pure):  1.00000    (1.00000)\n",
            "Precision:        1.00000\n",
            "Recall (pure):    1.00000    (1.00000)\n",
            "------------ STATS -------------\n",
            "Total #clTabperPrb:            1\n",
            "Total #ruleApps for clTab:     19\n",
            "Average #ruleApps for clTab:   19.00000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YES the provided relation does help the prover to find the proof for the entailment relation. Let's see the tableau proof for this (it is not a short proof)."
      ],
      "metadata": {
        "id": "BdVfVVsE1Pe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# viewing the proof\n",
        "show_tableau(mode2html[('align','yes')])"
      ],
      "metadata": {
        "id": "Vi6lUlig1Pe1",
        "colab": {
          "resources": {
            "http://localhost:8080/css/tableau.css": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90a5a275-705a-4eb5-d502-7d9e78f3ecd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".tableau {\n",
              "\ttext-align:center;\n",
              "\tdisplay:block;\n",
              "\t/*background-color: rgb(250, 230, 180);*/\n",
              "\tcolor: #000;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              ".tree {\n",
              "  vertical-align: top;\n",
              "\tdisplay: inline-block;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\tpadding-top: 15px; /*level distance*/\n",
              "\twhite-space: nowrap;\n",
              "\t/*border: 1px solid red;*/\n",
              "}\n",
              "\n",
              "\n",
              "/**************** DRAWING LINES*****************/\n",
              "/*We will use ::before and ::after to draw the connectors*/\n",
              ".tree::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; right: 50%;\n",
              "}\n",
              ".tree::after{\n",
              "    content: '';\n",
              "    position: absolute; top: 0;\n",
              "    border-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; left: 50%;\n",
              "}\n",
              "/*We need to remove left-right connectors from elements without\n",
              "any siblings*/\n",
              ".tree:only-of-type::after, .tree:only-of-type::before {\n",
              "    display:none;\n",
              "}\n",
              "\n",
              "/*Remove space from the top of single children*/\n",
              ".tree:only-child{ padding-top: 0;}\n",
              "\n",
              "/*Remove left connector from first child and\n",
              "right connector from last child*/\n",
              ".tree:first-child::before, .tree:last-child::after{\n",
              "\tborder: 0 none;\n",
              "}\n",
              "/*Adding back the vertical connector to the last nodes*/\n",
              ".tree:last-child::before{\n",
              "\tborder-right: 2px solid #aaa;\n",
              "\tborder-top-right-radius: 10px;\n",
              "}\n",
              "\n",
              ".tree:first-child::after{\n",
              "\tborder-top-left-radius: 10px;\n",
              "\tborder-left: 2px solid #aaa;\n",
              "}\n",
              "\n",
              "/*Time to add downward connectors from parents*/\n",
              ".subTrees::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-left: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px;\n",
              "\tleft: 50%;\n",
              "}\n",
              "\n",
              ".subTrees {\n",
              "    /*border: 1px solid green;*/\n",
              "    padding-top: 15px;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\twhite-space: nowrap;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/*********** NODE formatting ***********/\n",
              ".node {\n",
              "    display:inline-block;\n",
              "\tborder-radius: 3px; border: 1px solid #aaa;\n",
              "}\n",
              ".node_id {\n",
              "    font-family:\"Courier New\", Courier, monospace; color: #fff;\n",
              "    padding-left: 2px; background-color: #555;\n",
              "    border-radius: 3px 0px 0px 3px;\n",
              "}\n",
              ".modList, .argList, .llf {\n",
              "\tfont-family:\"Courier New\", Courier, monospace;\n",
              "\tborder-left: 2px solid #aaa; padding: 0px 3px 0px 3px;\n",
              "    margin-left: -4px;\n",
              "}\n",
              ".true >  .llf{ background-color:rgb(210,250,200); }\n",
              ".false > .llf{ background-color:rgb(250,210,200); }\n",
              ".modList{background-color:rgb(210,200,250);}\n",
              ".argList{background-color:rgb(250,230,150);}\n",
              "\n",
              ".source > span.source {\n",
              "    display: inline;\n",
              "\tfont-size:85%; color: #fff;\n",
              "\tborder: 1px solid #aaa;\n",
              "\tpadding: 0px 2px 2px 2px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 5px 5px;\n",
              "\tbackground-color:#555;\n",
              "}\n",
              "\n",
              "/************* Open branch and Closure ********************/\n",
              ".open_branch > i.fa.fa-unlock{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 200%;\n",
              "   padding-left: 4px; display: block;\n",
              "}\n",
              "\n",
              "div.open_branch {\n",
              "    font-family: \"Courier New\", Courier, monospace;\n",
              "    color: #999; font-weight: bold;\n",
              "}\n",
              "\n",
              ".closure > i.fa.fa-times-circle{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 170%;\n",
              "   padding-left: 4px;\n",
              "}\n",
              ".closer{\n",
              "  font-size:80%;\n",
              "  color: #aaa;\n",
              "  font-weight: bold;\n",
              "  border: 1px solid #aaa;\n",
              "  padding: 0px 3px 3px 3px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 7px 7px;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/******** Styling the problem ************/\n",
              "\n",
              ".problem {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              "    margin-left: auto;\n",
              "    margin-right: auto;\n",
              "\tpadding-bottom: 20px;\n",
              "}\n",
              "\n",
              ".premise {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              " \tbackground-color:rgb(210,250,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "\n",
              ".conclusion {\n",
              "\tdisplay:block;\n",
              "    text-align:center;\n",
              "\tborder-top: 3px solid #aaa;\n",
              "\tbackground-color:rgb(250,210,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/tableau.css\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css\">\n",
              "<title>Tableau</title>\n",
              "</head>\n",
              "<body><div class=\"tableau\">\n",
              "<div class=\"problem\">\n",
              "<div class=\"premise\">Two young women are sparring in a kickboxing fight</div>\n",
              "<div class=\"conclusion\">? Two women are sparring in a kickboxing match</div>\n",
              "</div>\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">1</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">two@(young@woman)@(be@(λ_2162,a@(kickboxing@fight)@(λ_2384,in@_2384@spar@_2162)))</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">2</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">two@woman@(be@(λ_2912,a@(kickboxing@match)@(λ_2384,in@_2384@spar@_2912)))</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">3</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">young@woman</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">tr_a[1]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">4</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_2162,a@(kickboxing@fight)@(λ_2384,in@_2384@spar@_2162))</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">tr_a[1]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">5</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">(λ_2162,a@(kickboxing@fight)@(λ_2384,in@_2384@spar@_2162))</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[4]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">6</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">a@(kickboxing@fight)@(λ_2384,in@_2384@spar@c1)</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[5]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">7</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">woman</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">int_mod_tr[3]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">8</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">young</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">int_mod_tr[3]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">9</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">kickboxing@fight</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">tr_a[6]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">10</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">(λ_2384,in@_2384@spar@c1)</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">tr_a[6]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">11</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">in@c2@spar@c1</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[10]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">12</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">fight</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">int_mod_tr[9]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">13</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">kickboxing</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">int_mod_tr[9]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">14</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">in@c2@spar</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_arg[11]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">15</span><span class=\"formula true\">\n",
              "<span class=\"modList\">in@c2</span>\n",
              "<span class=\"llf\">spar</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_mod[14]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">14</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">in@c2@spar</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">mods_vp[15]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">16</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_2162,a@(kickboxing@fight)@(λ_2384,in@_2384@spar@_2162))</span>\n",
              "<span class=\"argList\">c3</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon[1,2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">17</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_2912,a@(kickboxing@match)@(λ_2384,in@_2384@spar@_2912))</span>\n",
              "<span class=\"argList\">c3</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon[1,2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">20</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">(λ_2912,a@(kickboxing@match)@(λ_2384,in@_2384@spar@_2912))</span>\n",
              "<span class=\"argList\">c3</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[17]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">21</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">a@(kickboxing@match)@(λ_2384,in@_2384@spar@c3)</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[20]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">22</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">(λ_2162,a@(kickboxing@fight)@(λ_2384,in@_2384@spar@_2162))</span>\n",
              "<span class=\"argList\">c3</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[16]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">23</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">a@(kickboxing@fight)@(λ_2384,in@_2384@spar@c3)</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[22]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">24</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">a@(kickboxing@fight)</span>\n",
              "<span class=\"argList\">(λ_2384,in@_2384@spar@c3)</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">same_args_tf[23,21]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">25</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">a@(kickboxing@match)</span>\n",
              "<span class=\"argList\">(λ_2384,in@_2384@spar@c3)</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">same_args_tf[23,21]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">26</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">kickboxing@fight</span>\n",
              "<span class=\"argList\">c4</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon_fun[24,25]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">27</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">kickboxing@match</span>\n",
              "<span class=\"argList\">c4</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon_fun[24,25]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\"></div>\n",
              "<div class=\"closure\">\n",
              "<i class=\"fa fa-times-circle\"></i><div class=\"closer\">\n",
              "<div class=\"closer_rule\">cl_subsumption_complex</div>\n",
              "<div class=\"closer_ids\">[26,27]</div>\n",
              "</div>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">18</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">two@(young@woman)</span>\n",
              "<span class=\"argList\">be@(λ_2912,a@(kickboxing@match)@(λ_2384,in@_2384@spar@_2912))</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon[1,2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">19</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">two@woman</span>\n",
              "<span class=\"argList\">be@(λ_2912,a@(kickboxing@match)@(λ_2384,in@_2384@spar@_2912))</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon[1,2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\"></div>\n",
              "<div class=\"closure\">\n",
              "<i class=\"fa fa-times-circle\"></i><div class=\"closer\">\n",
              "<div class=\"closer_rule\">cl_subsumption_complex</div>\n",
              "<div class=\"closer_ids\">[18,19]</div>\n",
              "</div>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></body>\n",
              "</html>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general it is good to know how `.tableau_prove()` and `show_tableau` display tableau. `.tableau_prove()` runs LangPro from prolog with the provided input and creates xml and html files that display tableau. For example, `mode2html` is a dictioanry with mode keys (a combination of alignment flag and yes/no checking) and the corresponding path to html files. `show_tableau` simply takes the path to the html file and renders its content in the colab cell.  \n",
        "It is always a good practice to check out/log of `.tableau_prove()` because if LangPro errors for an unexpected input, this will be only visible in the out/log string. When LangPro errors usually the tableau html files are not changed and if one is not aware of the errorm, then `show_tableau` will display proof from the previous non-erronouns run of tableau with the same proble and alignment settings (e.g., see file names of html files)."
      ],
      "metadata": {
        "id": "b1sydg5axkVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filenames of the html files that contain colorful tableau proofs\n",
        "mode2html"
      ],
      "metadata": {
        "id": "d75HYoHbxs8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48495c64-4a71-4568-f4f4-879a8d799d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('align', 'yes'): '/content/LangPro/xml/tableau-44-yes-align.html',\n",
              " ('align', 'no'): '/content/LangPro/xml/tableau-44-no-align.html'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex7[4pt]: Providing missing knowledge\n",
        "\n",
        "Find two problem with IDs in [500-10000] intervals in train & trial parts (!) of SICK such that they are not correctly classified by the prover due to a missing lexical knowledge. Feed the prover with the required knowledge and demonstrate that the knowledge helps in solving the problems. You can use `.nli_prove` for a list of found problems and contrast two runs, with and without the added knowledge. Note that you can concatenate several knowldge. e.g., 'isa(fight,match),isa(match,fight)'  \n",
        "Note that besides the lack of lexical knowledge, there can be other reasons why proof was not found for a gold lable, e.g., syntactic trees obtained from a CCG parser was wrong, POS tagger was wrong, or LangPro doesn't have tableau rules that deals certain phenomena. When you cannot see how for a certain problem the lexical knowledge could help LangPro, skip the problem.\n",
        "\n",
        "**Hint**: You can get log of `nli_prove` and search with regex in it, but don't provide the code for this. We only want the code that uses two problem IDs and their corresponding knowledge and shows how adding the knowledge helps to predict the problems correctly."
      ],
      "metadata": {
        "id": "pcBwZf8V1Pe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################## EXERCISE 7 ##################################\n",
        "# INSERT YOUR CODE TO DISPLAY CONTRAST LIKE IT IS DONE WITH PROBLEM 44\n",
        "#first to result without added knowledge\n",
        "out, mode2html = lp.tableau_prove(4393)\n",
        "print(out) \n",
        "out, mode2html = lp.tableau_prove(4393,kb=\"isa(guy,man),isa(man,guy)\")   #provide information that a guy is a man\n",
        "print(out) \n",
        "show_tableau(mode2html[('align','yes')])\n"
      ],
      "metadata": {
        "id": "etSKOrUe1Pe3",
        "colab": {
          "resources": {
            "http://localhost:8080/css/tableau.css": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "711aa269-9064-4d6b-bf31-f490c52d594d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4393:     [yes], unknown,    open, 'Ter',24    XP: []\n",
            "      A man is riding a horse in a sandy land\n",
            "      A guy is riding a horse\n",
            "------------------------------------------------------ \n",
            " Gold\\Prover       YES       NO       UNK       DEF\n",
            "------------------------------------------------------ \n",
            " ENTAILMENT:        0        0        1 (0)      0 \n",
            "------------------------------------------------------ \n",
            " CONTRADICTION:     0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " NEUTRAL:           0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            "Total #problems:  1\n",
            "Accuracy (pure):  0.00000    (0.00000)\n",
            "Precision:        0.00000\n",
            "Recall (pure):    0.00000    (0.00000)\n",
            "------------ STATS -------------\n",
            "Total #clTabperPrb:            0\n",
            "Total #ruleApps for clTab:     0\n",
            "Average #ruleApps for clTab:   0.00000\n",
            "\n",
            "4393:     [yes],     yes,  closed, 'Ter',10    XP: [int(sandy),isa(guy,man),isa(man,guy)]\n",
            "------------------------------------------------------ \n",
            " Gold\\Prover       YES       NO       UNK       DEF\n",
            "------------------------------------------------------ \n",
            " ENTAILMENT:        1        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " CONTRADICTION:     0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " NEUTRAL:           0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            "Total #problems:  1\n",
            "Accuracy (pure):  1.00000    (1.00000)\n",
            "Precision:        1.00000\n",
            "Recall (pure):    1.00000    (1.00000)\n",
            "------------ STATS -------------\n",
            "Total #clTabperPrb:            1\n",
            "Total #ruleApps for clTab:     10\n",
            "Average #ruleApps for clTab:   10.00000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".tableau {\n",
              "\ttext-align:center;\n",
              "\tdisplay:block;\n",
              "\t/*background-color: rgb(250, 230, 180);*/\n",
              "\tcolor: #000;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              ".tree {\n",
              "  vertical-align: top;\n",
              "\tdisplay: inline-block;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\tpadding-top: 15px; /*level distance*/\n",
              "\twhite-space: nowrap;\n",
              "\t/*border: 1px solid red;*/\n",
              "}\n",
              "\n",
              "\n",
              "/**************** DRAWING LINES*****************/\n",
              "/*We will use ::before and ::after to draw the connectors*/\n",
              ".tree::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; right: 50%;\n",
              "}\n",
              ".tree::after{\n",
              "    content: '';\n",
              "    position: absolute; top: 0;\n",
              "    border-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; left: 50%;\n",
              "}\n",
              "/*We need to remove left-right connectors from elements without\n",
              "any siblings*/\n",
              ".tree:only-of-type::after, .tree:only-of-type::before {\n",
              "    display:none;\n",
              "}\n",
              "\n",
              "/*Remove space from the top of single children*/\n",
              ".tree:only-child{ padding-top: 0;}\n",
              "\n",
              "/*Remove left connector from first child and\n",
              "right connector from last child*/\n",
              ".tree:first-child::before, .tree:last-child::after{\n",
              "\tborder: 0 none;\n",
              "}\n",
              "/*Adding back the vertical connector to the last nodes*/\n",
              ".tree:last-child::before{\n",
              "\tborder-right: 2px solid #aaa;\n",
              "\tborder-top-right-radius: 10px;\n",
              "}\n",
              "\n",
              ".tree:first-child::after{\n",
              "\tborder-top-left-radius: 10px;\n",
              "\tborder-left: 2px solid #aaa;\n",
              "}\n",
              "\n",
              "/*Time to add downward connectors from parents*/\n",
              ".subTrees::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-left: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px;\n",
              "\tleft: 50%;\n",
              "}\n",
              "\n",
              ".subTrees {\n",
              "    /*border: 1px solid green;*/\n",
              "    padding-top: 15px;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\twhite-space: nowrap;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/*********** NODE formatting ***********/\n",
              ".node {\n",
              "    display:inline-block;\n",
              "\tborder-radius: 3px; border: 1px solid #aaa;\n",
              "}\n",
              ".node_id {\n",
              "    font-family:\"Courier New\", Courier, monospace; color: #fff;\n",
              "    padding-left: 2px; background-color: #555;\n",
              "    border-radius: 3px 0px 0px 3px;\n",
              "}\n",
              ".modList, .argList, .llf {\n",
              "\tfont-family:\"Courier New\", Courier, monospace;\n",
              "\tborder-left: 2px solid #aaa; padding: 0px 3px 0px 3px;\n",
              "    margin-left: -4px;\n",
              "}\n",
              ".true >  .llf{ background-color:rgb(210,250,200); }\n",
              ".false > .llf{ background-color:rgb(250,210,200); }\n",
              ".modList{background-color:rgb(210,200,250);}\n",
              ".argList{background-color:rgb(250,230,150);}\n",
              "\n",
              ".source > span.source {\n",
              "    display: inline;\n",
              "\tfont-size:85%; color: #fff;\n",
              "\tborder: 1px solid #aaa;\n",
              "\tpadding: 0px 2px 2px 2px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 5px 5px;\n",
              "\tbackground-color:#555;\n",
              "}\n",
              "\n",
              "/************* Open branch and Closure ********************/\n",
              ".open_branch > i.fa.fa-unlock{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 200%;\n",
              "   padding-left: 4px; display: block;\n",
              "}\n",
              "\n",
              "div.open_branch {\n",
              "    font-family: \"Courier New\", Courier, monospace;\n",
              "    color: #999; font-weight: bold;\n",
              "}\n",
              "\n",
              ".closure > i.fa.fa-times-circle{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 170%;\n",
              "   padding-left: 4px;\n",
              "}\n",
              ".closer{\n",
              "  font-size:80%;\n",
              "  color: #aaa;\n",
              "  font-weight: bold;\n",
              "  border: 1px solid #aaa;\n",
              "  padding: 0px 3px 3px 3px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 7px 7px;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/******** Styling the problem ************/\n",
              "\n",
              ".problem {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              "    margin-left: auto;\n",
              "    margin-right: auto;\n",
              "\tpadding-bottom: 20px;\n",
              "}\n",
              "\n",
              ".premise {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              " \tbackground-color:rgb(210,250,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "\n",
              ".conclusion {\n",
              "\tdisplay:block;\n",
              "    text-align:center;\n",
              "\tborder-top: 3px solid #aaa;\n",
              "\tbackground-color:rgb(250,210,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/tableau.css\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css\">\n",
              "<title>Tableau</title>\n",
              "</head>\n",
              "<body><div class=\"tableau\">\n",
              "<div class=\"problem\">\n",
              "<div class=\"premise\">A man is riding a horse in a sandy land</div>\n",
              "<div class=\"conclusion\">? A guy is riding a horse</div>\n",
              "</div>\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">1</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">a@man@(be@(λ_2150,a@(sandy@land)@(λ_2372,in@_2372@'ride@(a@horse)'@_2150)))</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">2</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">a@guy@(be@'ride@(a@horse)')</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">3</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_2150,a@(sandy@land)@(λ_2372,in@_2372@'ride@(a@horse)'@_2150))</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon_fun_some[1,2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">4</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">be@'ride@(a@horse)'</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon_fun_some[1,2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">5</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">man</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">up_mon_fun_some[1,2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">6</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">'ride@(a@horse)'</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[4]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">7</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">(λ_2150,a@(sandy@land)@(λ_2372,in@_2372@'ride@(a@horse)'@_2150))</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[3]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">8</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">a@(sandy@land)@(λ_2372,in@_2372@'ride@(a@horse)'@c1)</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[7]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">9</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">sandy@land</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">tr_a[8]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">10</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">(λ_2372,in@_2372@'ride@(a@horse)'@c1)</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">tr_a[8]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">11</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">in@c2@'ride@(a@horse)'@c1</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[10]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">12</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">land</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">int_mod_tr[9]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">13</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">sandy</span>\n",
              "<span class=\"argList\">c2</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">int_mod_tr[9]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">14</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">in@c2@'ride@(a@horse)'</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_arg[11]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">15</span><span class=\"formula true\">\n",
              "<span class=\"modList\">in@c2</span>\n",
              "<span class=\"llf\">'ride@(a@horse)'</span>\n",
              "<span class=\"argList\">c1</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_mod[14]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\"></div>\n",
              "<div class=\"closure\">\n",
              "<i class=\"fa fa-times-circle\"></i><div class=\"closer\">\n",
              "<div class=\"closer_rule\">cl_subcat</div>\n",
              "<div class=\"closer_ids\">[15,6]</div>\n",
              "</div>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></body>\n",
              "</html>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out, mode2html = lp.tableau_prove(4699)\n",
        "print(out) \n",
        "out, mode2html = lp.tableau_prove(4699,kb=\"isa(seashore,beach)\")   #provide information that the seashore is a beach\n",
        "print(out) \n",
        "show_tableau(mode2html[('align','yes')])"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/css/tableau.css": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IKMkbJ8wDycW",
        "outputId": "0ac07f82-5be8-4c92-e821-87a49b64703f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4699:     [yes], unknown,    open, 'Ter',62    XP: []\n",
            "      A group of boys is playing soccer on the seashore\n",
            "      A group of boys is playing soccer on the beach\n",
            "------------------------------------------------------ \n",
            " Gold\\Prover       YES       NO       UNK       DEF\n",
            "------------------------------------------------------ \n",
            " ENTAILMENT:        0        0        1 (0)      0 \n",
            "------------------------------------------------------ \n",
            " CONTRADICTION:     0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " NEUTRAL:           0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            "Total #problems:  1\n",
            "Accuracy (pure):  0.00000    (0.00000)\n",
            "Precision:        0.00000\n",
            "Recall (pure):    0.00000    (0.00000)\n",
            "------------ STATS -------------\n",
            "Total #clTabperPrb:            0\n",
            "Total #ruleApps for clTab:     0\n",
            "Average #ruleApps for clTab:   0.00000\n",
            "\n",
            "4699:     [yes],     yes,  closed, 'Ter',8     XP: [isa(seashore,beach)]\n",
            "------------------------------------------------------ \n",
            " Gold\\Prover       YES       NO       UNK       DEF\n",
            "------------------------------------------------------ \n",
            " ENTAILMENT:        1        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " CONTRADICTION:     0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            " NEUTRAL:           0        0        0 (0)      0 \n",
            "------------------------------------------------------ \n",
            "Total #problems:  1\n",
            "Accuracy (pure):  1.00000    (1.00000)\n",
            "Precision:        1.00000\n",
            "Recall (pure):    1.00000    (1.00000)\n",
            "------------ STATS -------------\n",
            "Total #clTabperPrb:            1\n",
            "Total #ruleApps for clTab:     8\n",
            "Average #ruleApps for clTab:   8.00000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".tableau {\n",
              "\ttext-align:center;\n",
              "\tdisplay:block;\n",
              "\t/*background-color: rgb(250, 230, 180);*/\n",
              "\tcolor: #000;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              ".tree {\n",
              "  vertical-align: top;\n",
              "\tdisplay: inline-block;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\tpadding-top: 15px; /*level distance*/\n",
              "\twhite-space: nowrap;\n",
              "\t/*border: 1px solid red;*/\n",
              "}\n",
              "\n",
              "\n",
              "/**************** DRAWING LINES*****************/\n",
              "/*We will use ::before and ::after to draw the connectors*/\n",
              ".tree::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; right: 50%;\n",
              "}\n",
              ".tree::after{\n",
              "    content: '';\n",
              "    position: absolute; top: 0;\n",
              "    border-top: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px; left: 50%;\n",
              "}\n",
              "/*We need to remove left-right connectors from elements without\n",
              "any siblings*/\n",
              ".tree:only-of-type::after, .tree:only-of-type::before {\n",
              "    display:none;\n",
              "}\n",
              "\n",
              "/*Remove space from the top of single children*/\n",
              ".tree:only-child{ padding-top: 0;}\n",
              "\n",
              "/*Remove left connector from first child and\n",
              "right connector from last child*/\n",
              ".tree:first-child::before, .tree:last-child::after{\n",
              "\tborder: 0 none;\n",
              "}\n",
              "/*Adding back the vertical connector to the last nodes*/\n",
              ".tree:last-child::before{\n",
              "\tborder-right: 2px solid #aaa;\n",
              "\tborder-top-right-radius: 10px;\n",
              "}\n",
              "\n",
              ".tree:first-child::after{\n",
              "\tborder-top-left-radius: 10px;\n",
              "\tborder-left: 2px solid #aaa;\n",
              "}\n",
              "\n",
              "/*Time to add downward connectors from parents*/\n",
              ".subTrees::before{\n",
              "\tcontent: '';\n",
              "\tposition: absolute; top: 0;\n",
              "\tborder-left: 2px solid #ccc;\n",
              "\twidth: 50%; height: 15px;\n",
              "\tleft: 50%;\n",
              "}\n",
              "\n",
              ".subTrees {\n",
              "    /*border: 1px solid green;*/\n",
              "    padding-top: 15px;\n",
              "\ttext-align: center;\n",
              "\tposition: relative;\n",
              "\twhite-space: nowrap;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/*********** NODE formatting ***********/\n",
              ".node {\n",
              "    display:inline-block;\n",
              "\tborder-radius: 3px; border: 1px solid #aaa;\n",
              "}\n",
              ".node_id {\n",
              "    font-family:\"Courier New\", Courier, monospace; color: #fff;\n",
              "    padding-left: 2px; background-color: #555;\n",
              "    border-radius: 3px 0px 0px 3px;\n",
              "}\n",
              ".modList, .argList, .llf {\n",
              "\tfont-family:\"Courier New\", Courier, monospace;\n",
              "\tborder-left: 2px solid #aaa; padding: 0px 3px 0px 3px;\n",
              "    margin-left: -4px;\n",
              "}\n",
              ".true >  .llf{ background-color:rgb(210,250,200); }\n",
              ".false > .llf{ background-color:rgb(250,210,200); }\n",
              ".modList{background-color:rgb(210,200,250);}\n",
              ".argList{background-color:rgb(250,230,150);}\n",
              "\n",
              ".source > span.source {\n",
              "    display: inline;\n",
              "\tfont-size:85%; color: #fff;\n",
              "\tborder: 1px solid #aaa;\n",
              "\tpadding: 0px 2px 2px 2px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 5px 5px;\n",
              "\tbackground-color:#555;\n",
              "}\n",
              "\n",
              "/************* Open branch and Closure ********************/\n",
              ".open_branch > i.fa.fa-unlock{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 200%;\n",
              "   padding-left: 4px; display: block;\n",
              "}\n",
              "\n",
              "div.open_branch {\n",
              "    font-family: \"Courier New\", Courier, monospace;\n",
              "    color: #999; font-weight: bold;\n",
              "}\n",
              "\n",
              ".closure > i.fa.fa-times-circle{\n",
              "   color: rgb(190,15,20);\n",
              "   font-size: 170%;\n",
              "   padding-left: 4px;\n",
              "}\n",
              ".closer{\n",
              "  font-size:80%;\n",
              "  color: #aaa;\n",
              "  font-weight: bold;\n",
              "  border: 1px solid #aaa;\n",
              "  padding: 0px 3px 3px 3px;\n",
              "\tfont-family: \"Courier New\", Courier, monospace;\n",
              "\tborder-radius: 0px 0px 7px 7px;\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "/******** Styling the problem ************/\n",
              "\n",
              ".problem {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              "    margin-left: auto;\n",
              "    margin-right: auto;\n",
              "\tpadding-bottom: 20px;\n",
              "}\n",
              "\n",
              ".premise {\n",
              "    text-align:center;\n",
              "\tdisplay:block;\n",
              " \tbackground-color:rgb(210,250,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "\n",
              ".conclusion {\n",
              "\tdisplay:block;\n",
              "    text-align:center;\n",
              "\tborder-top: 3px solid #aaa;\n",
              "\tbackground-color:rgb(250,210,200);\n",
              "\tpadding: 3px;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/tableau.css\">\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css\">\n",
              "<title>Tableau</title>\n",
              "</head>\n",
              "<body><div class=\"tableau\">\n",
              "<div class=\"problem\">\n",
              "<div class=\"premise\">A group of boys is playing soccer on the seashore</div>\n",
              "<div class=\"conclusion\">? A group of boys is playing soccer on the beach</div>\n",
              "</div>\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">1</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_2870,the@seashore@(λ_3026,on@_3026@'play@(a@soccer)'@_2870))@'a@(of@(s@boy)@group)'</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">2</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_3464,the@beach@(λ_3026,on@_3026@'play@(a@soccer)'@_3464))@'a@(of@(s@boy)@group)'</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">3</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_3464,the@beach@(λ_3026,on@_3026@'play@(a@soccer)'@_3464))</span>\n",
              "<span class=\"argList\">'a@(of@(s@boy)@group)'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_arg[2]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">4</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">(λ_3464,the@beach@(λ_3026,on@_3026@'play@(a@soccer)'@_3464))</span>\n",
              "<span class=\"argList\">'a@(of@(s@boy)@group)'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[3]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">5</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">the@beach@(λ_3026,on@_3026@'play@(a@soccer)'@'a@(of@(s@boy)@group)')</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[4]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">6</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">be@(λ_2870,the@seashore@(λ_3026,on@_3026@'play@(a@soccer)'@_2870))</span>\n",
              "<span class=\"argList\">'a@(of@(s@boy)@group)'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">push_arg[1]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">7</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">(λ_2870,the@seashore@(λ_3026,on@_3026@'play@(a@soccer)'@_2870))</span>\n",
              "<span class=\"argList\">'a@(of@(s@boy)@group)'</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">empty_mod[6]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">8</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">the@seashore@(λ_3026,on@_3026@'play@(a@soccer)'@'a@(of@(s@boy)@group)')</span>\n",
              "\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">pull_arg[7]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">9</span><span class=\"formula true\">\n",
              "\n",
              "<span class=\"llf\">the@seashore</span>\n",
              "<span class=\"argList\">(λ_3026,on@_3026@'play@(a@soccer)'@'a@(of@(s@boy)@group)')</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">same_args_tf[8,5]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\">\n",
              "<span class=\"node_id\">10</span><span class=\"formula false\">\n",
              "\n",
              "<span class=\"llf\">the@beach</span>\n",
              "<span class=\"argList\">(λ_3026,on@_3026@'play@(a@soccer)'@'a@(of@(s@boy)@group)')</span>\n",
              "</span>\n",
              "</div>\n",
              "<div class=\"source\"><span class=\"source\">same_args_tf[8,5]</span></div>\n",
              "<div class=\"subTrees\">\n",
              "<span class=\"tree\"><div class=\"node\"></div>\n",
              "<div class=\"closure\">\n",
              "<i class=\"fa fa-times-circle\"></i><div class=\"closer\">\n",
              "<div class=\"closer_rule\">cl_subsumption_complex</div>\n",
              "<div class=\"closer_ids\">[9,10]</div>\n",
              "</div>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></span>\n",
              "</div></body>\n",
              "</html>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}